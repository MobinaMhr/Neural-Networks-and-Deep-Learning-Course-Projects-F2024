{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport nibabel as nib\nimport numpy as np\nfrom torch.utils.data import Dataset\nfrom torchvision import transforms\nfrom PIL import Image","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T14:03:37.906539Z","iopub.execute_input":"2025-01-08T14:03:37.906897Z","iopub.status.idle":"2025-01-08T14:03:38.723120Z","shell.execute_reply.started":"2025-01-08T14:03:37.906870Z","shell.execute_reply":"2025-01-08T14:03:38.722002Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"TRAIN_ROOT_DIR = \"/kaggle/input/ixit2-slices/image slice-T2/\"\nTEST_ROOT_DIR  = \"/kaggle/input/brats20-dataset-training-validation\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T14:03:38.724501Z","iopub.execute_input":"2025-01-08T14:03:38.724863Z","iopub.status.idle":"2025-01-08T14:03:38.729453Z","shell.execute_reply.started":"2025-01-08T14:03:38.724832Z","shell.execute_reply":"2025-01-08T14:03:38.728041Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"class BrainTumorDataset(Dataset):\n    def __init__(self, train_root_dir, test_root_dir, mode=\"train\", transform=None):\n        self.train_root_dir = train_root_dir\n        self.test_root_dir = test_root_dir\n        self.mode = mode\n        self.transform = transform\n        self.image_paths = self._load_image_paths()\n\n    def _load_image_paths(self):\n        image_paths = []\n        if self.mode == \"train\":\n            for folder in os.listdir(self.train_root_dir):\n                folder_path = os.path.join(self.train_root_dir, folder)\n                for file_name in os.listdir(folder_path):\n                    if file_name.endswith('.png'):\n                        image_paths.append(os.path.join(folder_path, file_name))\n        elif self.mode == \"test\":\n            train_data_folder = os.path.join(self.test_root_dir, \"BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData\")\n            test_data_folder  = os.path.join(self.test_root_dir, \"BraTS2020_ValidationData/MICCAI_BraTS2020_ValidationData\")\n            for folder in os.listdir(train_data_folder):\n                folder_path = os.path.join(train_data_folder, folder)\n                if os.path.isfile(folder_path) and folder.endswith('.csv'):\n                    continue\n                for file_name in os.listdir(folder_path):\n                    if file_name.endswith('.nii'):\n                        image_paths.append(os.path.join(folder_path, file_name))\n            for folder in os.listdir(test_data_folder):\n                folder_path = os.path.join(test_data_folder, folder)\n                if os.path.isfile(folder_path) and folder.endswith('.csv'):\n                    continue\n                for file_name in os.listdir(folder_path):\n                    if file_name.endswith('.nii'):\n                        image_paths.append(os.path.join(folder_path, file_name))\n        return image_paths\n\n    def _load_nii_file(self, nii_path):\n        nii_data = nib.load(nii_path).get_fdata()\n        slices = []\n        for i in range(nii_data.shape[2]): \n            slice_data = nii_data[:, :, i]\n            min_val, max_val = np.min(slice_data), np.max(slice_data)\n            if max_val - min_val == 0:\n                slice_data = np.zeros_like(slice_data)\n            else:\n                slice_data = (slice_data - min_val) / (max_val - min_val)  # Normalize to [0, 1]\n            slice_image = Image.fromarray((slice_data * 255).astype(np.uint8)).convert(\"L\")\n            slices.append(slice_image)\n        return slices\n        \n    def __len__(self):\n        return len(self.image_paths)\n\n    def __getitem__(self, idx):\n        if self.mode == \"train\":\n            img_path = self.image_paths[idx]\n            image = Image.open(img_path).convert(\"RGB\")\n            if self.transform:\n                image = self.transform(image)\n            return {\"image\": image, \"path\": img_path}\n        elif self.mode == \"test\":\n            nii_path = self.image_paths[idx]\n            slices = self._load_nii_file(nii_path)\n            if self.transform:\n                slices = [self.transform(slice_image) for slice_image in slices]\n            return {\"slices\": slices, \"path\": nii_path}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T15:17:46.906427Z","iopub.execute_input":"2025-01-08T15:17:46.906785Z","iopub.status.idle":"2025-01-08T15:17:46.919497Z","shell.execute_reply.started":"2025-01-08T15:17:46.906754Z","shell.execute_reply":"2025-01-08T15:17:46.918319Z"}},"outputs":[],"execution_count":56},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.Resize((256, 256)),  # Resize to a fixed size\n    transforms.ToTensor(),         # Convert to tensor\n])\n\ntrain_dataset = BrainTumorDataset(\n    train_root_dir=TRAIN_ROOT_DIR,\n    test_root_dir=TEST_ROOT_DIR,\n    mode=\"train\",\n    transform=transform,\n)\n\ntrain_sample = train_dataset[0]\nprint(\"Train Image shape:\", train_sample[\"image\"].shape)\nprint(\"Train Image path:\", train_sample[\"path\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T15:17:48.119740Z","iopub.execute_input":"2025-01-08T15:17:48.120102Z","iopub.status.idle":"2025-01-08T15:17:48.578297Z","shell.execute_reply.started":"2025-01-08T15:17:48.120053Z","shell.execute_reply":"2025-01-08T15:17:48.576973Z"}},"outputs":[{"name":"stdout","text":"Train Image shape: torch.Size([3, 256, 256])\nTrain Image path: /kaggle/input/ixit2-slices/image slice-T2/IXI644-Guys-1121-DUAL_TSES_-s455_-0501-00005-000002-02/94.png\n","output_type":"stream"}],"execution_count":57},{"cell_type":"code","source":"test_dataset = BrainTumorDataset(\n    train_root_dir=TRAIN_ROOT_DIR,\n    test_root_dir=TEST_ROOT_DIR,\n    mode=\"test\",\n    transform=transform,\n)\n\ntest_sample = test_dataset[0]\nprint(\"Test NII Path:\", test_sample[\"path\"])\nprint(\"Number of slices in test sample:\", len(test_sample[\"slices\"]))\nprint(\"Shape of first slice:\", test_sample[\"slices\"][0].shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-08T15:17:49.203928Z","iopub.execute_input":"2025-01-08T15:17:49.204317Z","iopub.status.idle":"2025-01-08T15:17:50.099676Z","shell.execute_reply.started":"2025-01-08T15:17:49.204283Z","shell.execute_reply":"2025-01-08T15:17:50.097516Z"}},"outputs":[{"name":"stdout","text":"Test NII Path: /kaggle/input/brats20-dataset-training-validation/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData/BraTS20_Training_083/BraTS20_Training_083_flair.nii\nNumber of slices in test sample: 155\nShape of first slice: torch.Size([1, 256, 256])\n","output_type":"stream"}],"execution_count":58},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}