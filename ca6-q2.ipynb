{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2094438,"sourceType":"datasetVersion","datasetId":1255979}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from IPython.display import clear_output\n!pip install cleverhans\nclear_output()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T10:21:46.836485Z","iopub.execute_input":"2025-01-15T10:21:46.836849Z","iopub.status.idle":"2025-01-15T10:21:51.901007Z","shell.execute_reply.started":"2025-01-15T10:21:46.836816Z","shell.execute_reply":"2025-01-15T10:21:51.900132Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import numpy as np\nfrom tqdm import tqdm\nimport pandas as pd\n\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport matplotlib.pyplot as plt\nfrom torchvision.utils import make_grid\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader, random_split\n\nfrom cleverhans.torch.attacks.fast_gradient_method import fast_gradient_method\nfrom torch.optim.lr_scheduler import StepLR\n\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T10:21:51.902134Z","iopub.execute_input":"2025-01-15T10:21:51.902362Z","iopub.status.idle":"2025-01-15T10:21:56.352923Z","shell.execute_reply.started":"2025-01-15T10:21:51.902342Z","shell.execute_reply":"2025-01-15T10:21:56.352087Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"train_transform = transforms.Compose([transforms.ToTensor()])\n\ntrain_set = datasets.CIFAR10(root='../data/', train=True, download=True, transform=train_transform)\nprint(train_set.data.shape)\nprint(train_set.data.mean(axis=(0, 1, 2)) / 255)\nprint(train_set.data.std(axis=(0, 1, 2)) / 255)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T10:21:56.354651Z","iopub.execute_input":"2025-01-15T10:21:56.354995Z","iopub.status.idle":"2025-01-15T10:22:03.455807Z","shell.execute_reply.started":"2025-01-15T10:21:56.354974Z","shell.execute_reply":"2025-01-15T10:22:03.455053Z"}},"outputs":[{"name":"stdout","text":"Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../data/cifar-10-python.tar.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 170498071/170498071 [00:03<00:00, 49246707.08it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ../data/cifar-10-python.tar.gz to ../data/\n(50000, 32, 32, 3)\n[0.49139968 0.48215841 0.44653091]\n[0.24703223 0.24348513 0.26158784]\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"batch_size = 128\nmean       = [0.49139968, 0.48215841, 0.44653091]\nstd        = [0.24703223, 0.24348513, 0.26158784]\n\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize(mean, std)\n])\n\nCLASSES = [\n    'airplane', 'automobile', 'bird', 'cat', 'deer',\n    'dog', 'frog', 'horse', 'ship', 'truck'\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T10:22:03.457025Z","iopub.execute_input":"2025-01-15T10:22:03.457367Z","iopub.status.idle":"2025-01-15T10:22:03.461972Z","shell.execute_reply.started":"2025-01-15T10:22:03.457334Z","shell.execute_reply":"2025-01-15T10:22:03.461210Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def denormalize(img, mean, std):\n    img = img.numpy().transpose((1, 2, 0))\n    img = img * std + mean\n    return np.clip(img, 0, 1)\n\ndef show_samples(data_loader):\n    data_iter = iter(data_loader)\n    images, labels = next(data_iter)\n    images = images[:5]\n    labels = labels[:5]\n    fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n    for i, ax in enumerate(axes):\n        img = denormalize(images[i], mean, std)\n        ax.imshow(img)\n        ax.set_title(f\"{CLASSES[labels[i].item()]}\", fontsize=20)\n        ax.axis(\"off\")\n    plt.show()\n\ndef show_adv_images_with_labels(adv_examples, true_labels, pred_labels_orig, pred_labels_adv):\n    orig_images, adv_images = adv_examples[0]  # Example batch\n    fig, axes = plt.subplots(3, 5, figsize=(15, 8))\n    for i in range(5):\n        orig = denormalize(orig_images[i].detach().cpu(), mean, std)\n        adv = denormalize(adv_images[i].detach().cpu(), mean, std)\n        diff = np.abs(adv - orig)\n\n        true_label = CLASSES[true_labels[i]]\n        orig_pred_label = CLASSES[pred_labels_orig[i]]\n        adv_pred_label = CLASSES[pred_labels_adv[i]]\n\n        axes[0, i].imshow(orig)\n        axes[0, i].set_title(f\"True: {true_label}\\nPred: {orig_pred_label}\")\n        axes[0, i].axis(\"off\")\n        axes[1, i].imshow(adv)\n        axes[1, i].set_title(f\"Adversarial\\nPred: {adv_pred_label}\")\n        axes[1, i].axis(\"off\")\n        axes[2, i].imshow(diff)\n        axes[2, i].set_title(\"Difference\")\n        axes[2, i].axis(\"off\")\n    plt.tight_layout()\n    plt.show()\n\ndef visualize_adversarial_samples(generator, test_loader):\n    generator.eval()\n\n    images, labels = next(iter(test_loader))\n    images, labels = images[:5].to(device), labels[:5].to(device)\n    with torch.no_grad():\n        perturbations = generator(images)\n        adv_images = torch.clamp(images + perturbations, -1, 1)\n\n    images = images.cpu()\n    adv_images = adv_images.cpu()\n    perturbations = perturbations.cpu()\n\n    fig, axes = plt.subplots(3, 5, figsize=(15, 8))\n    for i in range(5):\n        axes[0, i].imshow(denormalize(images[i], mean, std))\n        axes[0, i].set_title(f\"Original: {CLASSES[labels[i]]}\")\n        axes[0, i].axis(\"off\")\n        axes[1, i].imshow(denormalize(adv_images[i], mean, std))\n        axes[1, i].set_title(\"Adversarial\")\n        axes[1, i].axis(\"off\")\n        axes[2, i].imshow(denormalize(perturbations[i], mean, std), cmap=\"seismic\")\n        axes[2, i].set_title(\"Perturbation\")\n        axes[2, i].axis(\"off\")\n    plt.tight_layout()\n    plt.show()\n\n# def plot_losses(epochs, g_losses, d_losses, g_accuracies):\n#     actual_epochs = len(g_losses)  # Number of completed epochs\n#     plt.figure(figsize=(12, 5))\n#     plt.subplot(1, 2, 1)\n#     plt.plot(range(1, actual_epochs + 1), g_losses, label='Generator Loss', color='blue')\n#     plt.plot(range(1, actual_epochs + 1), d_losses, label='Discriminator Loss', color='red')\n#     plt.xlabel('Epochs')\n#     plt.ylabel('Loss')\n#     plt.title('Generator and Discriminator Losses')\n#     plt.legend()\n#     plt.subplot(1, 2, 2)\n#     plt.plot(range(1, actual_epochs + 1), g_accuracies, label='Generator Accuracy', color='green')\n#     plt.xlabel('Epochs')\n#     plt.ylabel('Accuracy')\n#     plt.title('Generator Fooling Accuracy')\n#     plt.legend()    \n#     plt.tight_layout()\n#     plt.show()\n#     import matplotlib.pyplot as plt\n\ndef plot_losses(epochs, g_losses, d_losses, g_accuracies, model_accuracies, \n                attack_success_rates, val_g_losses, val_d_losses, \n                val_g_accuracies, val_model_accuracies, val_attack_success_rates):\n    \n    actual_epochs = len(g_losses)    \n    plt.figure(figsize=(18, 10))\n    \n    plt.subplot(2, 3, 1)\n    plt.plot(range(1, actual_epochs + 1), g_losses, label='Generator Loss', color='blue')\n    plt.plot(range(1, actual_epochs + 1), d_losses, label='Discriminator Loss', color='red')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.title('Generator and Discriminator Losses')\n    plt.legend()\n    \n    plt.subplot(2, 3, 2)\n    plt.plot(range(1, actual_epochs + 1), g_accuracies, label='Generator Accuracy', color='green')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.title('Generator Fooling Accuracy')\n    plt.legend()\n    \n    plt.subplot(2, 3, 3)\n    plt.plot(range(1, actual_epochs + 1), model_accuracies, label='Model Accuracy', color='purple')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.title('Model Accuracy')\n    plt.legend()\n    \n    plt.subplot(2, 3, 4)\n    plt.plot(range(1, actual_epochs + 1), attack_success_rates, label='Attack Success Rate', color='orange')\n    plt.xlabel('Epochs')\n    plt.ylabel('Success Rate')\n    plt.title('Attack Success Rates')\n    plt.legend()\n    \n    plt.subplot(2, 3, 5)\n    plt.plot(range(1, actual_epochs + 1), val_g_losses, label='Validation Generator Loss', color='blue')\n    plt.plot(range(1, actual_epochs + 1), val_d_losses, label='Validation Discriminator Loss', color='red')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.title('Validation Generator and Discriminator Losses')\n    plt.legend()\n    \n    plt.subplot(2, 3, 6)\n    plt.plot(range(1, actual_epochs + 1), val_g_accuracies, label='Validation Generator Accuracy', color='green')\n    plt.plot(range(1, actual_epochs + 1), val_model_accuracies, label='Validation Model Accuracy', color='purple')\n    plt.plot(range(1, actual_epochs + 1), val_attack_success_rates, label='Validation Attack Success Rate', color='orange')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy / Success Rate')\n    plt.title('Validation Metrics')\n    plt.legend()\n    \n    plt.tight_layout()\n    plt.show()\n\n\ndef plot_confidence_histograms(target_model, test_loader, generator):\n    normal_confidences = []\n    adversarial_confidences = []\n\n    generator.eval()\n    target_model.eval()\n    with torch.no_grad():\n        for images, labels in test_loader:\n            images, labels = images.to(device), labels.to(device)\n            perturbations = generator(images)\n            adv_images = torch.clamp(images + perturbations, -1, 1)\n            # Get softmax confidence for normal and adversarial images\n            normal_outputs = torch.softmax(target_model(images), dim=1)\n            adv_outputs = torch.softmax(target_model(adv_images), dim=1)\n\n            normal_confidences.extend(normal_outputs.max(1)[0].cpu().numpy())\n            adversarial_confidences.extend(adv_outputs.max(1)[0].cpu().numpy())\n    plt.figure(figsize=(10, 5))\n    plt.hist(adversarial_confidences, bins=20, alpha=0.7, label=\"Adversarial Samples\", color=\"red\")\n    plt.hist(normal_confidences, bins=20, alpha=0.7, label=\"Normal Samples\", color=\"blue\")\n    plt.xlabel(\"Confidence\")\n    plt.ylabel(\"Frequency\")\n    plt.title(\"Confidence Histogram: Normal vs Adversarial\")\n    plt.legend()\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T10:22:03.462836Z","iopub.execute_input":"2025-01-15T10:22:03.463127Z","iopub.status.idle":"2025-01-15T10:22:03.484893Z","shell.execute_reply.started":"2025-01-15T10:22:03.463099Z","shell.execute_reply":"2025-01-15T10:22:03.484111Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def attack_success_rate(model, adv_examples):\n    total, success = 0, 0\n    model.eval()\n    for orig_images, adv_images in adv_examples:\n        with torch.no_grad():\n            orig_preds = model(orig_images).argmax(dim=1)\n            adv_preds = model(adv_images).argmax(dim=1)\n            success += (orig_preds != adv_preds).sum().item()\n            total += orig_images.size(0)\n    return success / total\n\ndef calculate_attack_success(target_model, test_loader, generator):\n    overall_success = 0\n    per_class_success = np.zeros(10)\n    per_class_count = np.zeros(10)\n\n    generator.eval()\n    target_model.eval()\n    with torch.no_grad():\n        for images, labels in test_loader:\n            images, labels = images.to(device), labels.to(device)\n            perturbations = generator(images)\n            adv_images = torch.clamp(images + perturbations, -1, 1)\n            # Get predictions on adversarial samples\n            adv_outputs = target_model(adv_images)\n            _, adv_preds = adv_outputs.max(1)\n            fooled = (adv_preds != labels).cpu().numpy()\n            overall_success += fooled.sum()\n            for label, is_fooled in zip(labels.cpu().numpy(), fooled):\n                per_class_count[label] += 1\n                per_class_success[label] += is_fooled\n    overall_rate = overall_success / sum(per_class_count)\n    per_class_rate = per_class_success / per_class_count\n    return overall_rate, per_class_rate\n\ndef calculate_targeted_attack_success(target_model, test_loader, generator, target_class):\n    overall_success = 0\n    per_class_success = np.zeros(10)\n    per_class_count = np.zeros(10)\n\n    generator.eval()\n    target_model.eval()\n\n    with torch.no_grad():\n        for images, labels in test_loader:\n            images, labels = images.to(device), labels.to(device)\n            perturbations = generator(images)\n            adv_images = torch.clamp(images + perturbations, -1, 1)\n\n            # Get predictions on adversarial samples\n            adv_outputs = target_model(adv_images)\n            _, adv_preds = adv_outputs.max(1)\n\n            # Check if target model was successfully targeted\n            targeted = (adv_preds == target_class).cpu().numpy()\n            overall_success += targeted.sum()\n\n            # Update per-class metrics\n            for label, is_targeted in zip(labels.cpu().numpy(), targeted):\n                per_class_count[label] += 1\n                per_class_success[label] += is_targeted\n\n    overall_rate = overall_success / sum(per_class_count)\n    per_class_rate = per_class_success / per_class_count\n\n    return overall_rate, per_class_rate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T10:22:03.485750Z","iopub.execute_input":"2025-01-15T10:22:03.486029Z","iopub.status.idle":"2025-01-15T10:22:03.505595Z","shell.execute_reply.started":"2025-01-15T10:22:03.485998Z","shell.execute_reply":"2025-01-15T10:22:03.504758Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"dataset = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\nprint(dataset.data.shape)\nprint(dataset.data.mean(axis=(0, 1, 2)) / 255)\nprint(dataset.data.std(axis=(0, 1, 2)) / 255)\ntest_dataset = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n\n# Split training dataset into training and validation\ntrain_size = int(0.8 * len(dataset))\nval_size = len(dataset) - train_size\ntrain_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n\n# Create DataLoaders\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False)\ntest_loader  = DataLoader(test_dataset,  batch_size=batch_size, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T10:22:03.506396Z","iopub.execute_input":"2025-01-15T10:22:03.506622Z","iopub.status.idle":"2025-01-15T10:22:48.762971Z","shell.execute_reply.started":"2025-01-15T10:22:03.506594Z","shell.execute_reply":"2025-01-15T10:22:48.762270Z"}},"outputs":[{"name":"stdout","text":"Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 170498071/170498071 [00:41<00:00, 4152787.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/cifar-10-python.tar.gz to ./data\n(50000, 32, 32, 3)\n[0.49139968 0.48215841 0.44653091]\n[0.24703223 0.24348513 0.26158784]\nFiles already downloaded and verified\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# show_samples(train_loader)\n# show_samples(val_loader)\n# show_samples(test_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T10:22:48.765038Z","iopub.execute_input":"2025-01-15T10:22:48.765263Z","iopub.status.idle":"2025-01-15T10:22:48.768391Z","shell.execute_reply.started":"2025-01-15T10:22:48.765244Z","shell.execute_reply":"2025-01-15T10:22:48.767583Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"target_model = torch.hub.load(\n    \"chenyaofo/pytorch-cifar-models\", \"cifar10_resnet20\", pretrained=True\n).to(device)\ntarget_model.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T10:22:48.769477Z","iopub.execute_input":"2025-01-15T10:22:48.769665Z","iopub.status.idle":"2025-01-15T10:22:50.203188Z","shell.execute_reply.started":"2025-01-15T10:22:48.769648Z","shell.execute_reply":"2025-01-15T10:22:50.202464Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/hub.py:295: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n  warnings.warn(\nDownloading: \"https://github.com/chenyaofo/pytorch-cifar-models/zipball/master\" to /root/.cache/torch/hub/master.zip\nDownloading: \"https://github.com/chenyaofo/pytorch-cifar-models/releases/download/resnet/cifar10_resnet20-4118986f.pt\" to /root/.cache/torch/hub/checkpoints/cifar10_resnet20-4118986f.pt\n100%|██████████| 1.09M/1.09M [00:00<00:00, 33.6MB/s]\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"CifarResNet(\n  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (2): BasicBlock(\n      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (2): BasicBlock(\n      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (2): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=64, out_features=10, bias=True)\n)"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"# # Evaluate accuracy on test set\n\n# correct = 0\n# total = 0\n# with torch.no_grad():\n#     for images, labels in test_loader:\n#         images, labels = images.to(device), labels.to(device)\n#         outputs = target_model(images)\n#         _, predicted = torch.max(outputs.data, 1)\n#         total += labels.size(0)\n#         correct += (predicted == labels).sum().item()\n\n# print(f\"Test Accuracy: {100 * correct / total}%\")\n\n# ##################################################################### #\n\n# # Generate adversarial images using FGSM\n# epsilon = 0.01\n\n# adv_examples = []\n# true_labels = []\n# pred_labels_orig = []\n# pred_labels_adv = []\n\n# target_model.eval()\n# for images, labels in test_loader:\n#     images, labels = images.to(device), labels.to(device)\n\n#     adv_images = fast_gradient_method(target_model, images, epsilon, norm=np.inf)\n#     adv_examples.append((images, adv_images))\n#     true_labels.extend(labels.cpu().numpy())\n    \n#     with torch.no_grad():\n#         orig_preds = target_model(images).argmax(dim=1)\n#         adv_preds = target_model(adv_images).argmax(dim=1)\n#         pred_labels_orig.extend(orig_preds.cpu().numpy())\n#         pred_labels_adv.extend(adv_preds.cpu().numpy())\n\n# success_rate = attack_success_rate(target_model, adv_examples)\n# print(f\"Attack Success Rate: {success_rate * 100:.2f}%\")\n\n# ##################################################################### #\n\n# show_samples(train_loader)\n# show_samples(val_loader)\n# show_samples(test_loader)\n\n# show_adv_images_with_labels(adv_examples, true_labels, pred_labels_orig, pred_labels_adv)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T10:22:50.203950Z","iopub.execute_input":"2025-01-15T10:22:50.204158Z","iopub.status.idle":"2025-01-15T10:22:50.207707Z","shell.execute_reply.started":"2025-01-15T10:22:50.204140Z","shell.execute_reply":"2025-01-15T10:22:50.206972Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"class Generator(nn.Module):\n    def __init__(self):\n        super(Generator, self).__init__()\n        self.encoder = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1),  # 32x32 -> 16x16\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),  # 16x16 -> 8x8\n            nn.BatchNorm2d(128),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),\n            nn.BatchNorm2d(256),\n            nn.LeakyReLU(0.2, True),\n            nn.Conv2d(256, 512, kernel_size=3, stride=2, padding=1),\n            nn.BatchNorm2d(512)\n        )\n        self.decoder = nn.Sequential(\n            nn.ReLU(True),\n            nn.ConvTranspose2d(512, 256, kernel_size=3, stride=2, padding=1, output_padding=1),\n            nn.BatchNorm2d(256),\n            nn.Dropout(0.5),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1),  # Fixed input channels to 256\n            nn.BatchNorm2d(128),\n            nn.Dropout(0.5),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),  # Fixed input channels to 128\n            nn.BatchNorm2d(64),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(64, 3, kernel_size=3, stride=2, padding=1, output_padding=1),  # Fixed input channels to 64\n            nn.Tanh()\n        )\n\n    def forward(self, x):\n        encoded = self.encoder(x)\n        decoded = self.decoder(encoded)\n        return decoded\n\nclass Discriminator(nn.Module):\n    def __init__(self):\n        super(Discriminator, self).__init__()\n        self.model = nn.Sequential(\n            nn.Conv2d(3, 8, kernel_size=4, stride=2, padding=1),  # 32x32 -> 16x16\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(8, 16, kernel_size=4, stride=2, padding=1),  # 16x16 -> 8x8\n            nn.BatchNorm2d(16),  # Fixed input channels to match previous Conv2d output\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(16, 32, kernel_size=4, stride=2, padding=1),  # 8x8 -> 4x4\n            nn.InstanceNorm2d(32), ###### , negative_slope=0.2\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Flatten(), # x = x.view(x.size(0), -1)  \n            nn.Linear(4 * 4 * 32, 1)  # Linear layer for final output\n        )\n\n    def forward(self, x):\n        return self.model(x).view(-1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T10:22:50.208405Z","iopub.execute_input":"2025-01-15T10:22:50.208578Z","iopub.status.idle":"2025-01-15T10:22:50.229787Z","shell.execute_reply.started":"2025-01-15T10:22:50.208563Z","shell.execute_reply":"2025-01-15T10:22:50.229046Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# class Generator(nn.Module):\n#     def __init__(self):\n#         super(Generator, self).__init__()\n#         # Encoder\n#         self.enc1 = nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1)\n#         self.enc2 = self._encoder_block(64, 128)\n#         self.enc3 = self._encoder_block(128, 256)\n#         self.enc4 = self._encoder_block(256, 512)\n#         # Decoder\n#         self.dec1 = self._decoder_block(512, 256)\n#         self.dec2 = self._decoder_block(512, 128)\n#         self.dec3 = self._decoder_block(256, 64)\n#         self.dec4 = nn.Sequential(\n#             nn.ReLU(True),\n#             nn.ConvTranspose2d(128, 3, kernel_size=3, stride=2, padding=1, output_padding=1),\n#             nn.Tanh()\n#         )\n\n#     def _encoder_block(self, in_channels, out_channels):\n#         return nn.Sequential(\n#             nn.LeakyReLU(0.2, True),\n#             nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1),\n#             nn.BatchNorm2d(out_channels)\n#         )\n\n#     def _decoder_block(self, in_channels, out_channels):\n#         return nn.Sequential(\n#             nn.ReLU(True),\n#             nn.ConvTranspose2d(in_channels, out_channels, kernel_size=3, stride=2, padding=1, output_padding=1),\n#             nn.BatchNorm2d(out_channels),\n#             nn.Dropout(0.5)\n#         )\n\n#     def encoder(self, x):\n#         e1 = self.enc1(x)\n#         e2 = self.enc2(e1)\n#         e3 = self.enc3(e2)\n#         e4 = self.enc4(e3)\n#         return e1, e2, e3, e4\n\n#     def decoder(self, e1, e2, e3, e4):\n#         d1 = self.dec1(e4)\n#         d2 = self.dec2(torch.cat([d1, e3], 1))\n#         d3 = self.dec3(torch.cat([d2, e2], 1))\n#         d4 = self.dec4(torch.cat([d3, e1], 1))\n#         return d4\n\n#     def forward(self, x):\n#         e1, e2, e3, e4 = self.encoder(x)\n#         decoded = self.decoder(e1, e2, e3, e4)\n#         return decoded\n\n\n# class Discriminator(nn.Module):\n#     def __init__(self):\n#         super(Discriminator, self).__init__()\n\n#         self.conv1 = nn.Conv2d(3, 8, kernel_size=4, stride=2, padding=1)\n#         self.conv2 = self._discriminator_block(8, 16)\n#         self.conv3 = self._discriminator_block(16, 32)\n#         self.fc = nn.Linear(4 * 4 * 32, 1)\n\n#     def _discriminator_block(self, in_channels, out_channels):\n#         return nn.Sequential(\n#             nn.Conv2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1),\n#             nn.InstanceNorm2d(out_channels),\n#             nn.LeakyReLU(0.2, True)\n#         )\n\n#     def encoder(self, x):\n#         x = self.conv1(x)\n#         x = self.conv2(x)\n#         x = self.conv3(x)\n#         return x\n\n#     def decoder(self, x):\n#         x = x.view(x.size(0), -1)\n#         x = self.fc(x)\n#         return x\n\n#     def forward(self, x):\n#         encoded = self.encoder(x)\n#         decoded = self.decoder(encoded)\n#         return decoded","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T10:22:50.230413Z","iopub.execute_input":"2025-01-15T10:22:50.230620Z","iopub.status.idle":"2025-01-15T10:22:50.247037Z","shell.execute_reply.started":"2025-01-15T10:22:50.230601Z","shell.execute_reply":"2025-01-15T10:22:50.246380Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"# class LossFunctions:\n#     @staticmethod\n#     def gan_loss(discriminator, original_images, perturbations):\n#         mse_loss = nn.MSELoss()\n#         # Discriminator outputs for real images\n#         real_preds = discriminator(original_images)\n#         real_targets = torch.ones_like(real_preds)  # Targets for real images are 1\n#         real_loss = mse_loss(real_preds, real_targets)\n#         # print(f\"real_loss: {real_loss}\")\n#         # Discriminator outputs for fake images\n#         fake_images = original_images + perturbations\n#         fake_preds = discriminator(fake_images)\n#         fake_targets = torch.zeros_like(fake_preds)  # Targets for fake images are 0\n#         fake_loss = mse_loss(fake_preds, fake_targets)\n#         # print(f\"fake_loss: {fake_loss}\")\n#         # Combine real and fake losses\n#         total_gan_loss = real_loss + fake_loss\n#         # print(f\"total_gan_loss: {total_gan_loss}\")\n#         return total_gan_loss\n#     @staticmethod\n#     def adversarial_loss(target_model, adv_images, target_labels):\n#         outputs = target_model(adv_images)\n#         return F.cross_entropy(outputs, target_labels)\n#     @staticmethod\n#     def hinge_loss(perturbations, c):\n#         norm = torch.norm(perturbations.view(perturbations.size(0), -1), dim=1)  # L2 norm\n#         hinge = F.relu(norm - c)\n#         return torch.mean(hinge)\n#     @staticmethod\n#     def total_loss(discriminator, target_model, alpha, beta, c, original_images, perturbations, target_labels):\n#         adv_images = torch.clamp(original_images + perturbations, -1, 1)\n#         l_gan = LossFunctions.gan_loss(discriminator, original_images, perturbations)\n#         l_adv = LossFunctions.adversarial_loss(target_model, adv_images, target_labels)\n#         l_hinge = LossFunctions.hinge_loss(perturbations, c)\n#         return l_adv + alpha * l_gan + beta * l_hinge\n\nclass LossFunctions:\n    @staticmethod\n    def gan_loss():\n        return nn.MSELoss()\n\n    @staticmethod\n    def adv_loss(logits, target, num_classes=10, kappa=0):\n        target_one_hot = torch.eye(num_classes).type(logits.type())[target.long()]\n        real = torch.sum(target_one_hot * logits, 1)\n        other = torch.max((1 - target_one_hot) * logits - (target_one_hot * 10000), 1)[0]\n        kappa = torch.zeros_like(other).fill_(kappa)\n        return torch.sum(torch.max(real - other, kappa))\n\n    @staticmethod\n    def hinge_loss(perturb, c):\n        norm = torch.norm(perturb.view(perturb.size(0), -1), dim=1)\n        clamped = torch.clamp(norm - c, min=0)\n        return torch.mean(clamped)\n\n    @staticmethod\n    def total_loss(adv_loss_value, gan_loss_value, hinge_loss_value, alpha, beta):\n        return alpha * gan_loss_value + beta * hinge_loss_value + adv_loss_value","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T10:22:50.247817Z","iopub.execute_input":"2025-01-15T10:22:50.248046Z","iopub.status.idle":"2025-01-15T10:22:50.263812Z","shell.execute_reply.started":"2025-01-15T10:22:50.248028Z","shell.execute_reply":"2025-01-15T10:22:50.263134Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"def attack_success(model, adversarial_images, labels):\n    with torch.no_grad():\n        adv_preds = model(adversarial_images).argmax(dim=1)\n        success = (labels != adv_preds).sum().item()\n    return success\n\ndef train_epoch(epoch, G, D, train_loader, optimizer_G, optimizer_D, target_model, alpha, beta, epochs):\n    G.train()\n    D.train()\n    train_g_loss, train_d_loss, train_attack_success_counts = 0, 0, 0\n    tepoch = tqdm(train_loader, unit=\"batch\", desc=f\"Training Epoch {epoch+1}/{epochs}\", ncols=100, leave=False)\n    for batch_idx, (images, labels) in enumerate(tepoch):\n        images, labels = images.to(device), labels.to(device)\n        batch_size = images.size(0)\n\n        perturbations = G(images)\n        adversarial_images = images + perturbations\n\n        optimizer_D.zero_grad()\n        real_loss = LossFunctions.gan_loss()(D(images), torch.ones(batch_size, device=device))\n        fake_loss = LossFunctions.gan_loss()(D(adversarial_images.detach()), torch.zeros(batch_size, device=device))\n        d_loss = real_loss + fake_loss\n        d_loss.backward()\n        optimizer_D.step()\n\n        optimizer_G.zero_grad()\n        g_loss = LossFunctions.total_loss(\n            adv_loss_value=LossFunctions.adv_loss(target_model(adversarial_images), labels), # /4\n            gan_loss_value=LossFunctions.gan_loss()(D(adversarial_images), torch.ones(batch_size, device=device)), \n            hinge_loss_value=LossFunctions.hinge_loss(perturbations, c), \n            alpha=alpha, beta=beta)\n        g_loss.backward()\n        optimizer_G.step()\n\n        train_g_loss += g_loss.item()\n        train_d_loss += d_loss.item()\n        train_attack_success_counts += attack_success(target_model, adversarial_images, labels)\n        tepoch.set_postfix({'Batch': batch_idx + 1, 'G_Loss': g_loss.item(), 'D_Loss': d_loss.item()})\n\n    train_g_loss /= len(train_loader)\n    train_d_loss /= len(train_loader)\n    train_attack_success_rate = train_attack_success_counts / len(train_dataset)\n    return train_g_loss, train_d_loss, train_attack_success_rate\n\ndef validate_epoch(G, D, val_loader, target_model, alpha, beta):\n    G.eval()\n    D.eval()\n    val_g_loss, val_d_loss, val_attack_success_counts = 0, 0, 0\n    with torch.no_grad():\n        for val_images, val_labels in val_loader:\n            val_images, val_labels = val_images.to(device), val_labels.to(device)\n            batch_size = val_images.size(0)\n\n            val_perturbations = G(val_images)\n            val_adversarial_images = val_images + val_perturbations\n            val_g_loss_batch = LossFunctions.total_loss(\n                adv_loss_value=LossFunctions.adv_loss(target_model(val_adversarial_images), val_labels), # / 4\n                gan_loss_value=LossFunctions.gan_loss()(D(val_adversarial_images), torch.ones(batch_size, device=device)), \n                hinge_loss_value=LossFunctions.hinge_loss(val_perturbations, c), \n                alpha=alpha, beta=beta\n            )\n            val_real_loss = LossFunctions.gan_loss()(D(val_images), torch.ones(batch_size, device=device))\n            val_fake_loss = LossFunctions.gan_loss()(D(val_adversarial_images), torch.zeros(batch_size, device=device))\n            val_d_loss_batch = val_real_loss + val_fake_loss\n\n            val_g_loss += val_g_loss_batch.item()\n            val_d_loss += val_d_loss_batch.item()\n            val_attack_success_counts += attack_success(target_model, val_adversarial_images, val_labels)\n\n    val_g_loss /= len(val_loader)\n    val_d_loss /= len(val_loader)\n    val_attack_success_rate = val_attack_success_counts / len(val_dataset)\n    return val_g_loss, val_d_loss, val_attack_success_rate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T10:23:56.997326Z","iopub.execute_input":"2025-01-15T10:23:56.997646Z","iopub.status.idle":"2025-01-15T10:23:57.008862Z","shell.execute_reply.started":"2025-01-15T10:23:56.997625Z","shell.execute_reply":"2025-01-15T10:23:57.008015Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"G = Generator().to(device)\nD = Discriminator().to(device)\n\nepochs = 50 \nlr = 0.001\nalpha = 1.0 # param alpha: Weight for adversarial loss (LGAN) \nbeta = 10.0 # param beta: Weight for hinge loss (Lhinge)\nc = 8/255   # param c: Hinge loss bound\npatience = 12\n8 / (255 * torch.tensor(std).max().item())\noptimizer_G = optim.Adam(G.parameters(), lr=lr, betas=(0.5, 0.999)) # , betas=(0.5, 0.999)\noptimizer_D = optim.Adam(D.parameters(), lr=lr, betas=(0.5, 0.999)) # , betas=(0.5, 0.999)\n\ng_scheduler = StepLR(optimizer_G, step_size=10, gamma=0.5)\nd_scheduler = StepLR(optimizer_D, step_size=10, gamma=0.5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T10:23:57.103737Z","iopub.execute_input":"2025-01-15T10:23:57.104013Z","iopub.status.idle":"2025-01-15T10:23:57.144391Z","shell.execute_reply.started":"2025-01-15T10:23:57.103989Z","shell.execute_reply":"2025-01-15T10:23:57.143774Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"best_val_loss = float('inf')\npatience_counter = 0\ng_losses, d_losses, g_accuracies = [], [], []\nval_g_losses, val_d_losses = [], []\nattack_success_rates, val_attack_success_rates = [], []\n# g_accuracies, val_g_accuracies = [], []\n# model_accuracies, val_model_accuracies = [], []\n\nfor epoch in range(epochs):\n    g_loss, d_loss, attack_success_rate = train_epoch(\n        epoch, G, D, train_loader, optimizer_G, optimizer_D, target_model, alpha, beta, epochs\n    )\n    g_losses.append(g_loss)\n    d_losses.append(d_loss)\n    attack_success_rates.append(attack_success_rate)\n    \n    val_g_loss, val_d_loss, val_attack_success_rate = validate_epoch(\n        G, D, val_loader, target_model, alpha, beta\n    )\n    val_g_losses.append(val_g_loss)\n    val_d_losses.append(val_d_loss)\n    val_attack_success_rates.append(val_attack_success_rate)\n    \n    print(f\"Epoch {epoch+1}/{epochs} | g_loss: {g_loss:.4f}, d_loss: {d_loss:.4f}, val_g_loss: {val_g_loss:.4f}, val_d_loss: {val_d_loss:.4f}, attack_success_rate: {attack_success_rate:.4f}, val_attack_success_rate: {val_attack_success_rate:.4f}\")    \n    \n    g_scheduler.step()\n    print(f\"Learning rate for generator: {g_scheduler.get_last_lr()[0]}\") \n    d_scheduler.step()\n    print(f\"Learning rate for discriminator: {d_scheduler.get_last_lr()[0]}\")\n\n    if val_g_loss < best_val_loss:\n        best_val_loss = val_g_loss\n        patience_counter = 0\n        torch.save(G.state_dict(), 'best_generator.pth')\n        torch.save(D.state_dict(), 'best_discriminator.pth')\n    else:\n        print(f\"Patience counter: {patience_counter + 1}/{patience}\")\n        patience_counter += 1\n\n    if patience_counter >= patience:\n        print(f\"Early stopping triggered after {epoch + 1} epochs.\")\n        break\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T10:23:58.335719Z","iopub.execute_input":"2025-01-15T10:23:58.336028Z","iopub.status.idle":"2025-01-15T10:38:25.358199Z","shell.execute_reply.started":"2025-01-15T10:23:58.336003Z","shell.execute_reply":"2025-01-15T10:38:25.357371Z"}},"outputs":[{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1/50 | g_loss: 177.7887, d_loss: 0.0625, val_g_loss: 127.6785, val_d_loss: 0.1876, attack_success_rate: 0.8558, val_attack_success_rate: 0.8796\nLearning rate for generator: 0.001\nLearning rate for discriminator: 0.001\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2/50 | g_loss: 128.8635, d_loss: 0.0070, val_g_loss: 127.7232, val_d_loss: 0.3758, attack_success_rate: 0.8796, val_attack_success_rate: 0.8627\nLearning rate for generator: 0.001\nLearning rate for discriminator: 0.001\nPatience counter: 1/12\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3/50 | g_loss: 117.8836, d_loss: 0.0033, val_g_loss: 108.1271, val_d_loss: 0.5656, attack_success_rate: 0.8918, val_attack_success_rate: 0.9140\nLearning rate for generator: 0.001\nLearning rate for discriminator: 0.001\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Epoch 4/50 | g_loss: 110.0651, d_loss: 0.0023, val_g_loss: 105.8318, val_d_loss: 0.7594, attack_success_rate: 0.9018, val_attack_success_rate: 0.9025\nLearning rate for generator: 0.001\nLearning rate for discriminator: 0.001\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Epoch 5/50 | g_loss: 105.9447, d_loss: 0.0024, val_g_loss: 103.7827, val_d_loss: 0.7654, attack_success_rate: 0.9042, val_attack_success_rate: 0.8896\nLearning rate for generator: 0.001\nLearning rate for discriminator: 0.001\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Epoch 6/50 | g_loss: 102.5892, d_loss: 0.0022, val_g_loss: 98.2279, val_d_loss: 0.9216, attack_success_rate: 0.9100, val_attack_success_rate: 0.9146\nLearning rate for generator: 0.001\nLearning rate for discriminator: 0.001\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Epoch 7/50 | g_loss: 100.1873, d_loss: 0.0019, val_g_loss: 100.2916, val_d_loss: 0.9272, attack_success_rate: 0.9130, val_attack_success_rate: 0.8944\nLearning rate for generator: 0.001\nLearning rate for discriminator: 0.001\nPatience counter: 1/12\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Epoch 8/50 | g_loss: 98.2279, d_loss: 0.0320, val_g_loss: 95.9791, val_d_loss: 0.6366, attack_success_rate: 0.9153, val_attack_success_rate: 0.9121\nLearning rate for generator: 0.001\nLearning rate for discriminator: 0.001\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Epoch 9/50 | g_loss: 95.7753, d_loss: 0.0007, val_g_loss: 97.0234, val_d_loss: 0.7622, attack_success_rate: 0.9190, val_attack_success_rate: 0.9026\nLearning rate for generator: 0.001\nLearning rate for discriminator: 0.001\nPatience counter: 1/12\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Epoch 10/50 | g_loss: 93.4074, d_loss: 0.0004, val_g_loss: 93.3772, val_d_loss: 0.8455, attack_success_rate: 0.9228, val_attack_success_rate: 0.9305\nLearning rate for generator: 0.0005\nLearning rate for discriminator: 0.0005\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Epoch 11/50 | g_loss: 87.3444, d_loss: 0.0003, val_g_loss: 91.8116, val_d_loss: 0.7741, attack_success_rate: 0.9313, val_attack_success_rate: 0.9283\nLearning rate for generator: 0.0005\nLearning rate for discriminator: 0.0005\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Epoch 12/50 | g_loss: 85.3443, d_loss: 0.0003, val_g_loss: 91.5227, val_d_loss: 0.8257, attack_success_rate: 0.9358, val_attack_success_rate: 0.9141\nLearning rate for generator: 0.0005\nLearning rate for discriminator: 0.0005\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Epoch 13/50 | g_loss: 84.3291, d_loss: 0.0002, val_g_loss: 90.8536, val_d_loss: 0.8824, attack_success_rate: 0.9354, val_attack_success_rate: 0.9298\nLearning rate for generator: 0.0005\nLearning rate for discriminator: 0.0005\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Epoch 14/50 | g_loss: 82.8046, d_loss: 0.0002, val_g_loss: 90.4333, val_d_loss: 0.8888, attack_success_rate: 0.9387, val_attack_success_rate: 0.9254\nLearning rate for generator: 0.0005\nLearning rate for discriminator: 0.0005\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Epoch 15/50 | g_loss: 81.3173, d_loss: 0.0002, val_g_loss: 96.2805, val_d_loss: 0.8760, attack_success_rate: 0.9413, val_attack_success_rate: 0.9136\nLearning rate for generator: 0.0005\nLearning rate for discriminator: 0.0005\nPatience counter: 1/12\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Epoch 16/50 | g_loss: 80.1763, d_loss: 0.0004, val_g_loss: 89.8060, val_d_loss: 0.8166, attack_success_rate: 0.9432, val_attack_success_rate: 0.9183\nLearning rate for generator: 0.0005\nLearning rate for discriminator: 0.0005\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Epoch 17/50 | g_loss: 79.7859, d_loss: 0.0005, val_g_loss: 90.2172, val_d_loss: 0.9186, attack_success_rate: 0.9420, val_attack_success_rate: 0.9268\nLearning rate for generator: 0.0005\nLearning rate for discriminator: 0.0005\nPatience counter: 1/12\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Epoch 18/50 | g_loss: 78.2738, d_loss: 0.0004, val_g_loss: 89.6943, val_d_loss: 0.9325, attack_success_rate: 0.9459, val_attack_success_rate: 0.9228\nLearning rate for generator: 0.0005\nLearning rate for discriminator: 0.0005\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Epoch 19/50 | g_loss: 76.6595, d_loss: 0.0005, val_g_loss: 89.5431, val_d_loss: 0.9513, attack_success_rate: 0.9480, val_attack_success_rate: 0.9101\nLearning rate for generator: 0.0005\nLearning rate for discriminator: 0.0005\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Epoch 20/50 | g_loss: 76.0191, d_loss: 0.0005, val_g_loss: 89.6071, val_d_loss: 0.9624, attack_success_rate: 0.9497, val_attack_success_rate: 0.9200\nLearning rate for generator: 0.00025\nLearning rate for discriminator: 0.00025\nPatience counter: 1/12\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Epoch 21/50 | g_loss: 71.9701, d_loss: 0.0001, val_g_loss: 89.3043, val_d_loss: 0.9174, attack_success_rate: 0.9543, val_attack_success_rate: 0.9023\nLearning rate for generator: 0.00025\nLearning rate for discriminator: 0.00025\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Epoch 22/50 | g_loss: 70.2891, d_loss: 0.0001, val_g_loss: 86.2133, val_d_loss: 0.9542, attack_success_rate: 0.9581, val_attack_success_rate: 0.9169\nLearning rate for generator: 0.00025\nLearning rate for discriminator: 0.00025\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Epoch 23/50 | g_loss: 68.9296, d_loss: 0.0001, val_g_loss: 85.8705, val_d_loss: 0.9404, attack_success_rate: 0.9596, val_attack_success_rate: 0.9274\nLearning rate for generator: 0.00025\nLearning rate for discriminator: 0.00025\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Epoch 24/50 | g_loss: 68.6006, d_loss: 0.0001, val_g_loss: 86.5614, val_d_loss: 0.9316, attack_success_rate: 0.9600, val_attack_success_rate: 0.9068\nLearning rate for generator: 0.00025\nLearning rate for discriminator: 0.00025\nPatience counter: 1/12\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Epoch 25/50 | g_loss: 67.2730, d_loss: 0.0001, val_g_loss: 90.5688, val_d_loss: 0.9324, attack_success_rate: 0.9638, val_attack_success_rate: 0.8962\nLearning rate for generator: 0.00025\nLearning rate for discriminator: 0.00025\nPatience counter: 2/12\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Epoch 26/50 | g_loss: 66.6695, d_loss: 0.0002, val_g_loss: 89.0233, val_d_loss: 0.8952, attack_success_rate: 0.9641, val_attack_success_rate: 0.9006\nLearning rate for generator: 0.00025\nLearning rate for discriminator: 0.00025\nPatience counter: 3/12\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Epoch 27/50 | g_loss: 65.8928, d_loss: 0.0002, val_g_loss: 87.9851, val_d_loss: 0.9544, attack_success_rate: 0.9651, val_attack_success_rate: 0.9125\nLearning rate for generator: 0.00025\nLearning rate for discriminator: 0.00025\nPatience counter: 4/12\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Epoch 28/50 | g_loss: 65.5668, d_loss: 0.0001, val_g_loss: 90.2211, val_d_loss: 0.9200, attack_success_rate: 0.9651, val_attack_success_rate: 0.8973\nLearning rate for generator: 0.00025\nLearning rate for discriminator: 0.00025\nPatience counter: 5/12\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Epoch 29/50 | g_loss: 64.9021, d_loss: 0.0002, val_g_loss: 87.7271, val_d_loss: 0.9379, attack_success_rate: 0.9671, val_attack_success_rate: 0.9124\nLearning rate for generator: 0.00025\nLearning rate for discriminator: 0.00025\nPatience counter: 6/12\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Epoch 30/50 | g_loss: 64.5692, d_loss: 0.0001, val_g_loss: 87.7028, val_d_loss: 0.9552, attack_success_rate: 0.9666, val_attack_success_rate: 0.9086\nLearning rate for generator: 0.000125\nLearning rate for discriminator: 0.000125\nPatience counter: 7/12\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Epoch 31/50 | g_loss: 62.8874, d_loss: 0.0000, val_g_loss: 87.7161, val_d_loss: 0.9440, attack_success_rate: 0.9698, val_attack_success_rate: 0.9065\nLearning rate for generator: 0.000125\nLearning rate for discriminator: 0.000125\nPatience counter: 8/12\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Epoch 32/50 | g_loss: 61.8717, d_loss: 0.0000, val_g_loss: 87.4521, val_d_loss: 0.9680, attack_success_rate: 0.9697, val_attack_success_rate: 0.9020\nLearning rate for generator: 0.000125\nLearning rate for discriminator: 0.000125\nPatience counter: 9/12\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Epoch 33/50 | g_loss: 61.4419, d_loss: 0.0000, val_g_loss: 88.6769, val_d_loss: 0.9542, attack_success_rate: 0.9726, val_attack_success_rate: 0.8944\nLearning rate for generator: 0.000125\nLearning rate for discriminator: 0.000125\nPatience counter: 10/12\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Epoch 34/50 | g_loss: 60.9985, d_loss: 0.0000, val_g_loss: 91.8770, val_d_loss: 0.9487, attack_success_rate: 0.9717, val_attack_success_rate: 0.8840\nLearning rate for generator: 0.000125\nLearning rate for discriminator: 0.000125\nPatience counter: 11/12\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Epoch 35/50 | g_loss: 60.8303, d_loss: 0.0000, val_g_loss: 87.7607, val_d_loss: 0.9569, attack_success_rate: 0.9720, val_attack_success_rate: 0.9031\nLearning rate for generator: 0.000125\nLearning rate for discriminator: 0.000125\nPatience counter: 12/12\nEarly stopping triggered after 35 epochs.\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"# best_val_loss = float('inf')\n# patience_counter = 0\n# g_losses, d_losses, g_accuracies = [], [], []\n# val_g_losses, val_d_losses = [], []\n# attack_success_rates, val_attack_success_rates = [], []\n# # g_accuracies, val_g_accuracies = [], []\n# # model_accuracies, val_model_accuracies = [], []\n# for epoch in range(epochs):\n#     g_loss, d_loss, attack_success_rate = train_epoch(\n#         epoch, G, D, train_loader, optimizer_G, optimizer_D, target_model, alpha, beta\n#     )\n#     g_losses.append(g_loss)\n#     d_losses.append(d_loss)\n#     attack_success_rates.append(attack_success_rate)\n    \n#     val_g_loss, val_d_loss, val_attack_success_rate = validate_epoch(\n#         G, D, val_loader, target_model, alpha, beta\n#     )\n#     val_g_losses.append(val_g_loss)\n#     val_d_losses.append(val_d_loss)\n#     val_attack_success_rates.append(val_attack_success_rate)\n    \n#     print(f\"Epoch {epoch+1}/{epochs} | g_loss: {g_loss:.4f}, d_loss: {d_loss:.4f}, val_g_loss: {val_g_loss:.4f}, val_d_loss: {val_d_loss:.4f}, attack_success_rate: {attack_success_rate:.4f}, val_attack_success_rate: {val_attack_success_rate:.4f}\")    \n#     if val_g_loss < best_val_loss:\n#         best_val_loss = val_g_loss\n#         patience_counter = 0\n#         torch.save(G.state_dict(), 'best_generator.pth')\n#         torch.save(D.state_dict(), 'best_discriminator.pth')\n#     else:\n#         print(f\"Patience counter: {patience_counter + 1}/{patience}\")\n#         patience_counter += 1\n\n#     if patience_counter >= patience:\n#         print(f\"Early stopping triggered after {epoch + 1} epochs.\")\n#         print(\"Early stopping triggered.\")\n#         break","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"actual_epochs = len(g_losses)    \nplt.figure(figsize=(18, 10))\n\nplt.subplot(2, 3, 1)\nplt.plot(range(1, actual_epochs + 1), g_losses, label='Generator Loss', color='blue')\nplt.plot(range(1, actual_epochs + 1), d_losses, label='Discriminator Loss', color='red')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('Generator and Discriminator Losses')\nplt.legend()\n\nplt.subplot(2, 3, 2)\nplt.plot(range(1, actual_epochs + 1), attack_success_rates, label='Attack Success Rate', color='orange')\nplt.plot(range(1, actual_epochs + 1), val_attack_success_rates, label='Validation Attack Success Rate', color='green')\nplt.xlabel('Epochs')\nplt.ylabel('Success Rate')\nplt.title('Attack Success Rates')\nplt.legend()\n\nplt.subplot(2, 3, 3)\nplt.plot(range(1, actual_epochs + 1), val_g_losses, label='Validation Generator Loss', color='blue')\nplt.plot(range(1, actual_epochs + 1), val_d_losses, label='Validation Discriminator Loss', color='red')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('Validation Generator and Discriminator Losses')\nplt.legend()\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# def train_gan(\n#     G, D, target_model, train_loader, val_loader,\n#     epochs, optimizer_G, optimizer_D, c, alpha, beta, \n#     g_scheduler, d_scheduler, patience\n# ):\n#     g_losses, d_losses, g_accuracies = [], [], []\n#     val_g_losses, val_d_losses, val_g_accuracies = [], [], []\n#     model_accuracies, attack_success_rates = [], []\n#     val_model_accuracies, val_attack_success_rates = [], []\n#     best_g_loss, best_d_loss = float('inf'), float('inf')\n#     epochs_no_improve = 0\n\n#     for epoch in range(epochs):\n#         correct_adv, correct_benign, total_samples = 0, 0, 0\n#         g_loss_epoch, d_loss_epoch = 0.0, 0.0\n\n#         tepoch = tqdm(train_loader, unit=\"batch\", desc=f\"Epoch {epoch+1}/{epochs}\", ncols=100, leave=False)\n\n#         for batch_idx, (images, labels) in enumerate(tepoch):\n#             images, labels = images.to(device), labels.to(device)\n#             G.train()\n#             D.train()\n#             target_model.eval()\n        \n#             \"\"\"\n#             Generator Update\n#             \"\"\"\n#             optimizer_G.zero_grad()\n#             perturbations = G(images)  # Recompute perturbations for generator update\n#             g_loss = LossFunctions.total_loss(\n#                 D, target_model,\n#                 alpha, beta, c, images, perturbations, labels\n#             )\n#             g_loss.backward()\n#             optimizer_G.step()\n#             \"\"\"\n#             Discriminator Update\n#             \"\"\"\n#             optimizer_D.zero_grad()\n#             with torch.no_grad():  # Disable gradient tracking for generator during discriminator update\n#                 perturbations = G(images)\n#                 adv_images = torch.clamp(images + perturbations, -1, 1)\n        \n#             d_loss = LossFunctions.gan_loss(D, images, perturbations)\n#             d_loss.backward()\n#             optimizer_D.step() \n\n            \n#             # Track losses and accuracy\n#             g_loss_epoch += g_loss.item()\n#             d_loss_epoch += d_loss.item()\n        \n#             with torch.no_grad():\n#                 benign_output = target_model(images)\n#                 _, benign_predicted = benign_output.max(1)\n#                 adv_output = target_model(adv_images)\n#                 _, adv_predicted = adv_output.max(1)\n        \n#                 correct_benign += (benign_predicted == labels).sum().item()\n#                 correct_adv += (adv_predicted != benign_predicted).sum().item()\n#                 total_samples += labels.size(0)\n        \n#             tepoch.set_postfix({'Batch': batch_idx + 1, 'G_Loss': g_loss.item(), 'D_Loss': d_loss.item()})\n        \n#         g_losses.append(g_loss_epoch / len(train_loader))\n#         d_losses.append(d_loss_epoch / len(train_loader))\n#         # len(train_loader):313 O total_samples:40000\n#         print(f\"len(train_loader):{len(train_loader)} O total_samples:{total_samples}\")\n#         print(f\"correct_adv:{correct_adv} O total_samples:{total_samples}\")\n#         g_accuracies.append(correct_adv / total_samples)\n#         model_accuracies.append(correct_benign / total_samples)\n#         attack_success_rates.append(correct_adv / total_samples)\n\n#         G.eval()\n#         D.eval()\n#         target_model.eval()\n#         val_g_loss_epoch, val_d_loss_epoch = 0.0, 0.0\n#         val_correct_adv, val_correct_benign, val_samples = 0, 0, 0\n#         with torch.no_grad():\n#             for val_images, val_labels in val_loader:\n#                 val_images, val_labels = val_images.to(device), val_labels.to(device)\n\n#                 val_perturbations = G(val_images)\n#                 val_adv_images = torch.clamp(val_images + val_perturbations, -1, 1)\n\n#                 val_d_loss = LossFunctions.gan_loss(D, val_images, val_perturbations)\n#                 val_g_loss = LossFunctions.total_loss(\n#                     D, target_model,\n#                     alpha, beta, c, val_images, val_perturbations, val_labels\n#                 )\n\n#                 val_g_loss_epoch += val_g_loss.item()\n#                 val_d_loss_epoch += val_d_loss.item()\n\n#                 val_benign_output = target_model(val_images)\n#                 _, val_benign_predicted = val_benign_output.max(1)\n#                 val_adv_output = target_model(val_adv_images)\n#                 _, val_adv_predicted = val_adv_output.max(1)\n\n#                 val_correct_benign += (val_benign_predicted == val_labels).sum().item()\n#                 val_correct_adv += (val_adv_predicted != val_labels).sum().item()\n#                 val_samples += val_labels.size(0)\n\n#         g_scheduler.step()\n#         d_scheduler.step()\n        \n#         val_g_losses.append(val_g_loss_epoch / len(val_loader))\n#         val_d_losses.append(val_d_loss_epoch / len(val_loader))\n#         val_g_accuracies.append(val_correct_adv / val_samples)\n#         val_model_accuracies.append(val_correct_benign / val_samples)\n#         val_attack_success_rates.append(val_correct_adv / val_samples)\n\n#         print(f\"Epoch [{epoch+1}/{epochs}], \"\n#               f\"Train G_Loss: {g_losses[-1]:.4f}, D_Loss: {d_losses[-1]:.4f}, Model Accuracy: {model_accuracies[-1]:.4f}, \"\n#               f\"Attack Success Rate: {attack_success_rates[-1]:.4f}, \"\n#               f\"Val G_Loss: {val_g_losses[-1]:.4f}, Val D_Loss: {val_d_losses[-1]:.4f}, \"\n#               f\"Val Model Accuracy: {val_model_accuracies[-1]:.4f}, Val Attack Success Rate: {val_attack_success_rates[-1]:.4f}\")\n#         if val_g_losses[-1] < best_g_loss or val_d_losses[-1] < best_d_loss:\n#             best_g_loss = min(val_g_losses[-1], best_g_loss)\n#             best_d_loss = min(val_d_losses[-1], best_d_loss)\n#             epochs_no_improve = 0\n#         else:\n#             epochs_no_improve += 1\n#             print(f\"Epochs without improvement: {epochs_no_improve}/{patience}\")\n#             if epochs_no_improve >= patience:\n#                 print(f\"Early stopping triggered after {epoch + 1} epochs.\")\n#                 break\n#     return (g_losses, d_losses, g_accuracies, model_accuracies, attack_success_rates,\n#             val_g_losses, val_d_losses, val_g_accuracies, val_model_accuracies, val_attack_success_rates)\n\n# (g_losses, d_losses, g_accuracies, model_accuracies, attack_success_rates, \n#  val_g_losses, val_d_losses, val_g_accuracies, val_model_accuracies, \n#  val_attack_success_rates) = train_gan(\n#     G, D, target_model, train_loader, val_loader,\n#     epochs, optimizer_G, optimizer_D, c, alpha, beta, \n#     g_scheduler, d_scheduler, patience\n# )\n\n# plot_losses(\n#     epochs, g_losses, d_losses, g_accuracies, model_accuracies, \n#     attack_success_rates, val_g_losses, val_d_losses, \n#     val_g_accuracies, val_model_accuracies, val_attack_success_rates\n# )","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"overall_rate, per_class_rate = calculate_attack_success(target_model, test_loader, generator)\n\nprint(f\"Overall Attack Success Rate: {overall_rate * 100:.2f}%\")\nfor i, class_name in enumerate(CLASSES):\n    print(f\"Class {class_name}: {per_class_rate[i] * 100:.2f}%\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"visualize_adversarial_samples(generator, test_loader)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_confidence_histograms(target_model, test_loader, generator)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# def train_gan(\n#     generator, discriminator, target_model, train_loader, \n#     epochs, g_optimizer, d_optimizer, c, alpha, beta, \n#     g_scheduler, d_scheduler, patience\n# ):\n#     g_losses, d_losses, g_accuracies = [], [], []\n#     best_g_loss, best_d_loss = float('inf'), float('inf')\n#     epochs_no_improve = 0\n\n#     for epoch in range(epochs):\n#         correct_adv = 0\n#         g_loss_epoch, d_loss_epoch = 0.0, 0.0\n#         tepoch = tqdm(train_loader, unit=\"batch\", desc=f\"Epoch {epoch+1}/{epochs}\", ncols=100, leave=False)\n\n#         generator.train()\n#         discriminator.train()\n#         for batch_idx, (images, labels) in enumerate(tepoch):\n#             images, labels = images.to(device), labels.to(device)\n\n#             perturbations = generator(images)\n#             adv_images = torch.clamp(images + perturbations, -1, 1)\n\n#             d_optimizer.zero_grad()\n#             d_loss = LossFunctions.gan_loss(\n#                 discriminator, images, perturbations\n#             )\n#             d_loss.backward()\n#             d_optimizer.step()\n\n#             g_optimizer.zero_grad()\n#             g_loss = LossFunctions.total_loss(\n#                 discriminator, target_model, \n#                 alpha, beta, c, images, perturbations\n#             )\n#             g_loss.backward()\n#             g_optimizer.step()\n\n#             g_loss_epoch += g_loss.item()\n#             d_loss_epoch += d_loss.item()\n#             adv_output = target_model(adv_images)\n#             _, predicted = adv_output.max(1)\n#             correct_adv += (predicted != labels).sum().item()\n#             tepoch.set_postfix({'Batch': batch_idx + 1, 'G_Loss': g_loss.item(), 'D_Loss': d_loss.item()})\n\n#         g_losses.append(g_loss_epoch / len(train_loader))\n#         d_losses.append(d_loss_epoch / len(train_loader))\n#         g_accuracies.append(correct_adv / len(train_loader))\n        \n#         print(f\"Epoch [{epoch+1}/{epochs}], Generator Loss: {g_losses[-1]:.4f}, Discriminator Loss: {d_losses[-1]:.4f}, Fooling Accuracy: {g_accuracies[-1]:.4f}\")\n#         generator.eval()\n#         g_scheduler.step()\n        \n#         discriminator.eval()\n#         d_scheduler.step()\n\n#         if g_losses[-1] < best_g_loss or d_losses[-1] < best_d_loss:\n#             best_g_loss = min(g_losses[-1], best_g_loss)\n#             best_d_loss = min(d_losses[-1], best_d_loss)\n#             epochs_no_improve = 0\n#         else:\n#             print(f\"Epochs without improvement: {epochs_no_improve + 1}/{patience}\")\n#             epochs_no_improve += 1\n#             if epochs_no_improve >= patience:\n#                 print(f\"Early stopping triggered after {epoch + 1} epochs.\")\n#                 break\n\n#     return g_losses, d_losses, g_accuracies\n\n# g_losses, d_losses, g_accuracies = train_gan(\n#     generator, discriminator, target_model, train_loader, \n#     epochs, g_optimizer, d_optimizer, c, alpha, beta, \n#     g_scheduler, d_scheduler, patience\n# )\n\n# plot_losses(epochs, g_losses, d_losses, g_accuracies)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# target_class = 0  # Example: Force adversarial images to be classified as \"airplane\" (class 0)\n# fooling_loss = adv_loss_fn(adv_output, torch.full_like(labels, target_class))\n\n# generator = Generator().to(device)\n# discriminator = Discriminator().to(device)\n\n# epochs = 50 \n# lr = 0.001\n# alpha = 1.0  # Weight for GAN loss\n# beta = 10.0  # Weight for hinge loss\n# # c = 0.1  # Perturbation bound\n# c = 8/255 # Perturbation bound (c) = 8/255 for CIFAR-10\n\n# g_optimizer = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n# d_optimizer = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n\n# g_scheduler = StepLR(g_optimizer, step_size=10, gamma=0.5)\n# d_scheduler = StepLR(d_optimizer, step_size=10, gamma=0.5)\n\n# g_losses, d_losses, g_accuracies = train_gan(\n#     generator, discriminator, target_model, train_loader, \n#     epochs, g_optimizer, d_optimizer, c, alpha, beta, \n#     g_scheduler, d_scheduler, patience\n# )\n\n# plot_losses(epochs, g_losses, d_losses, g_accuracies)\n# overall_rate, per_class_rate = calculate_targeted_attack_success(target_model, test_loader, generator, target_class)\n\n# print(f\"Overall Targeted Attack Success Rate: {overall_rate * 100:.2f}%\")\n# for i, class_name in enumerate(CLASSES):\n#     print(f\"Class {class_name}: {per_class_rate[i] * 100:.2f}%\")\n\n# visualize_adversarial_samples(generator, test_loader)\n# plot_confidence_histograms(target_model, test_loader, generator)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}