{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2094438,"sourceType":"datasetVersion","datasetId":1255979}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from IPython.display import clear_output\n!pip install cleverhans\nclear_output()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T12:18:12.793348Z","iopub.execute_input":"2025-01-13T12:18:12.793671Z","iopub.status.idle":"2025-01-13T12:18:17.584701Z","shell.execute_reply.started":"2025-01-13T12:18:12.793641Z","shell.execute_reply":"2025-01-13T12:18:17.583826Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"import numpy as np\nfrom tqdm import tqdm\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport matplotlib.pyplot as plt\nfrom torchvision.utils import make_grid\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader, random_split\n\nfrom cleverhans.torch.attacks.fast_gradient_method import fast_gradient_method\nfrom torch.optim.lr_scheduler import StepLR\n\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T12:18:17.585707Z","iopub.execute_input":"2025-01-13T12:18:17.585926Z","iopub.status.idle":"2025-01-13T12:18:21.685527Z","shell.execute_reply.started":"2025-01-13T12:18:17.585900Z","shell.execute_reply":"2025-01-13T12:18:21.684856Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"train_transform = transforms.Compose([transforms.ToTensor()])\n\ntrain_set = datasets.CIFAR10(root='../data/', train=True, download=True, transform=train_transform)\nprint(train_set.data.shape)\nprint(train_set.data.mean(axis=(0, 1, 2)) / 255)\nprint(train_set.data.std(axis=(0, 1, 2)) / 255)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T12:18:21.686815Z","iopub.execute_input":"2025-01-13T12:18:21.687126Z","iopub.status.idle":"2025-01-13T12:18:28.837698Z","shell.execute_reply.started":"2025-01-13T12:18:21.687106Z","shell.execute_reply":"2025-01-13T12:18:28.836937Z"}},"outputs":[{"name":"stdout","text":"Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../data/cifar-10-python.tar.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 170498071/170498071 [00:03<00:00, 48224823.07it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ../data/cifar-10-python.tar.gz to ../data/\n(50000, 32, 32, 3)\n[0.49139968 0.48215841 0.44653091]\n[0.24703223 0.24348513 0.26158784]\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"batch_size = 128\n\nmean = [0.49139968, 0.48215841, 0.44653091]\nstd = [0.24703223, 0.24348513, 0.26158784]\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize(mean, std)\n])\n\nCLASSES = [\n    'airplane', 'automobile', 'bird', 'cat', 'deer',\n    'dog', 'frog', 'horse', 'ship', 'truck'\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T12:18:28.838824Z","iopub.execute_input":"2025-01-13T12:18:28.839099Z","iopub.status.idle":"2025-01-13T12:18:28.843488Z","shell.execute_reply.started":"2025-01-13T12:18:28.839078Z","shell.execute_reply":"2025-01-13T12:18:28.842741Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def denormalize(img, mean, std):\n    img = img.numpy().transpose((1, 2, 0))\n    img = img * std + mean\n    return np.clip(img, 0, 1)\n\ndef show_samples(data_loader):\n    data_iter = iter(data_loader)\n    images, labels = next(data_iter)\n    images = images[:5]\n    labels = labels[:5]\n    fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n    for i, ax in enumerate(axes):\n        img = denormalize(images[i], mean, std)\n        ax.imshow(img)\n        ax.set_title(f\"{CLASSES[labels[i].item()]}\", fontsize=20)\n        ax.axis(\"off\")\n    plt.show()\n\ndef show_adv_images_with_labels(adv_examples, true_labels, pred_labels_orig, pred_labels_adv):\n    orig_images, adv_images = adv_examples[0]  # Example batch\n    fig, axes = plt.subplots(3, 5, figsize=(15, 8))\n    for i in range(5):\n        orig = denormalize(orig_images[i].detach().cpu(), mean, std)\n        adv = denormalize(adv_images[i].detach().cpu(), mean, std)\n        diff = np.abs(adv - orig)\n\n        true_label = CLASSES[true_labels[i]]\n        orig_pred_label = CLASSES[pred_labels_orig[i]]\n        adv_pred_label = CLASSES[pred_labels_adv[i]]\n\n        axes[0, i].imshow(orig)\n        axes[0, i].set_title(f\"True: {true_label}\\nPred: {orig_pred_label}\")\n        axes[0, i].axis(\"off\")\n        axes[1, i].imshow(adv)\n        axes[1, i].set_title(f\"Adversarial\\nPred: {adv_pred_label}\")\n        axes[1, i].axis(\"off\")\n        axes[2, i].imshow(diff)\n        axes[2, i].set_title(\"Difference\")\n        axes[2, i].axis(\"off\")\n    plt.tight_layout()\n    plt.show()\n\ndef visualize_adversarial_samples(generator, test_loader):\n    generator.eval()\n\n    images, labels = next(iter(test_loader))\n    images, labels = images[:5].to(device), labels[:5].to(device)\n    with torch.no_grad():\n        perturbations = generator(images)\n        adv_images = torch.clamp(images + perturbations, -1, 1)\n\n    images = images.cpu()\n    adv_images = adv_images.cpu()\n    perturbations = perturbations.cpu()\n\n    fig, axes = plt.subplots(3, 5, figsize=(15, 8))\n    for i in range(5):\n        axes[0, i].imshow(denormalize(images[i], mean, std))\n        axes[0, i].set_title(f\"Original: {CLASSES[labels[i]]}\")\n        axes[0, i].axis(\"off\")\n        axes[1, i].imshow(denormalize(adv_images[i], mean, std))\n        axes[1, i].set_title(\"Adversarial\")\n        axes[1, i].axis(\"off\")\n        axes[2, i].imshow(denormalize(perturbations[i], mean, std), cmap=\"seismic\")\n        axes[2, i].set_title(\"Perturbation\")\n        axes[2, i].axis(\"off\")\n    plt.tight_layout()\n    plt.show()\n\n# def plot_losses(epochs, g_losses, d_losses, g_accuracies):\n#     actual_epochs = len(g_losses)  # Number of completed epochs\n#     plt.figure(figsize=(12, 5))\n#     plt.subplot(1, 2, 1)\n#     plt.plot(range(1, actual_epochs + 1), g_losses, label='Generator Loss', color='blue')\n#     plt.plot(range(1, actual_epochs + 1), d_losses, label='Discriminator Loss', color='red')\n#     plt.xlabel('Epochs')\n#     plt.ylabel('Loss')\n#     plt.title('Generator and Discriminator Losses')\n#     plt.legend()\n#     plt.subplot(1, 2, 2)\n#     plt.plot(range(1, actual_epochs + 1), g_accuracies, label='Generator Accuracy', color='green')\n#     plt.xlabel('Epochs')\n#     plt.ylabel('Accuracy')\n#     plt.title('Generator Fooling Accuracy')\n#     plt.legend()    \n#     plt.tight_layout()\n#     plt.show()\n#     import matplotlib.pyplot as plt\n\ndef plot_losses(epochs, g_losses, d_losses, g_accuracies, model_accuracies, \n                attack_success_rates, val_g_losses, val_d_losses, \n                val_g_accuracies, val_model_accuracies, val_attack_success_rates):\n    \n    actual_epochs = len(g_losses)    \n    plt.figure(figsize=(18, 10))\n    \n    plt.subplot(2, 3, 1)\n    plt.plot(range(1, actual_epochs + 1), g_losses, label='Generator Loss', color='blue')\n    plt.plot(range(1, actual_epochs + 1), d_losses, label='Discriminator Loss', color='red')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.title('Generator and Discriminator Losses')\n    plt.legend()\n    \n    plt.subplot(2, 3, 2)\n    plt.plot(range(1, actual_epochs + 1), g_accuracies, label='Generator Accuracy', color='green')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.title('Generator Fooling Accuracy')\n    plt.legend()\n    \n    plt.subplot(2, 3, 3)\n    plt.plot(range(1, actual_epochs + 1), model_accuracies, label='Model Accuracy', color='purple')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.title('Model Accuracy')\n    plt.legend()\n    \n    plt.subplot(2, 3, 4)\n    plt.plot(range(1, actual_epochs + 1), attack_success_rates, label='Attack Success Rate', color='orange')\n    plt.xlabel('Epochs')\n    plt.ylabel('Success Rate')\n    plt.title('Attack Success Rates')\n    plt.legend()\n    \n    plt.subplot(2, 3, 5)\n    plt.plot(range(1, actual_epochs + 1), val_g_losses, label='Validation Generator Loss', color='blue')\n    plt.plot(range(1, actual_epochs + 1), val_d_losses, label='Validation Discriminator Loss', color='red')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.title('Validation Generator and Discriminator Losses')\n    plt.legend()\n    \n    plt.subplot(2, 3, 6)\n    plt.plot(range(1, actual_epochs + 1), val_g_accuracies, label='Validation Generator Accuracy', color='green')\n    plt.plot(range(1, actual_epochs + 1), val_model_accuracies, label='Validation Model Accuracy', color='purple')\n    plt.plot(range(1, actual_epochs + 1), val_attack_success_rates, label='Validation Attack Success Rate', color='orange')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy / Success Rate')\n    plt.title('Validation Metrics')\n    plt.legend()\n    \n    plt.tight_layout()\n    plt.show()\n\n\ndef plot_confidence_histograms(target_model, test_loader, generator):\n    normal_confidences = []\n    adversarial_confidences = []\n\n    generator.eval()\n    target_model.eval()\n    with torch.no_grad():\n        for images, labels in test_loader:\n            images, labels = images.to(device), labels.to(device)\n            perturbations = generator(images)\n            adv_images = torch.clamp(images + perturbations, -1, 1)\n            # Get softmax confidence for normal and adversarial images\n            normal_outputs = torch.softmax(target_model(images), dim=1)\n            adv_outputs = torch.softmax(target_model(adv_images), dim=1)\n\n            normal_confidences.extend(normal_outputs.max(1)[0].cpu().numpy())\n            adversarial_confidences.extend(adv_outputs.max(1)[0].cpu().numpy())\n    plt.figure(figsize=(10, 5))\n    plt.hist(adversarial_confidences, bins=20, alpha=0.7, label=\"Adversarial Samples\", color=\"red\")\n    plt.hist(normal_confidences, bins=20, alpha=0.7, label=\"Normal Samples\", color=\"blue\")\n    plt.xlabel(\"Confidence\")\n    plt.ylabel(\"Frequency\")\n    plt.title(\"Confidence Histogram: Normal vs Adversarial\")\n    plt.legend()\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T12:18:28.844301Z","iopub.execute_input":"2025-01-13T12:18:28.844506Z","iopub.status.idle":"2025-01-13T12:18:28.866333Z","shell.execute_reply.started":"2025-01-13T12:18:28.844488Z","shell.execute_reply":"2025-01-13T12:18:28.865544Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def attack_success_rate(model, adv_examples):\n    total, success = 0, 0\n    model.eval()\n    for orig_images, adv_images in adv_examples:\n        with torch.no_grad():\n            orig_preds = model(orig_images).argmax(dim=1)\n            adv_preds = model(adv_images).argmax(dim=1)\n            success += (orig_preds != adv_preds).sum().item()\n            total += orig_images.size(0)\n    return success / total\n\ndef calculate_attack_success(target_model, test_loader, generator):\n    overall_success = 0\n    per_class_success = np.zeros(10)\n    per_class_count = np.zeros(10)\n\n    generator.eval()\n    target_model.eval()\n    with torch.no_grad():\n        for images, labels in test_loader:\n            images, labels = images.to(device), labels.to(device)\n            perturbations = generator(images)\n            adv_images = torch.clamp(images + perturbations, -1, 1)\n            # Get predictions on adversarial samples\n            adv_outputs = target_model(adv_images)\n            _, adv_preds = adv_outputs.max(1)\n            fooled = (adv_preds != labels).cpu().numpy()\n            overall_success += fooled.sum()\n            for label, is_fooled in zip(labels.cpu().numpy(), fooled):\n                per_class_count[label] += 1\n                per_class_success[label] += is_fooled\n    overall_rate = overall_success / sum(per_class_count)\n    per_class_rate = per_class_success / per_class_count\n    return overall_rate, per_class_rate\n\ndef calculate_targeted_attack_success(target_model, test_loader, generator, target_class):\n    overall_success = 0\n    per_class_success = np.zeros(10)\n    per_class_count = np.zeros(10)\n\n    generator.eval()\n    target_model.eval()\n\n    with torch.no_grad():\n        for images, labels in test_loader:\n            images, labels = images.to(device), labels.to(device)\n            perturbations = generator(images)\n            adv_images = torch.clamp(images + perturbations, -1, 1)\n\n            # Get predictions on adversarial samples\n            adv_outputs = target_model(adv_images)\n            _, adv_preds = adv_outputs.max(1)\n\n            # Check if target model was successfully targeted\n            targeted = (adv_preds == target_class).cpu().numpy()\n            overall_success += targeted.sum()\n\n            # Update per-class metrics\n            for label, is_targeted in zip(labels.cpu().numpy(), targeted):\n                per_class_count[label] += 1\n                per_class_success[label] += is_targeted\n\n    overall_rate = overall_success / sum(per_class_count)\n    per_class_rate = per_class_success / per_class_count\n\n    return overall_rate, per_class_rate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T12:18:28.867207Z","iopub.execute_input":"2025-01-13T12:18:28.867455Z","iopub.status.idle":"2025-01-13T12:18:28.895369Z","shell.execute_reply.started":"2025-01-13T12:18:28.867426Z","shell.execute_reply":"2025-01-13T12:18:28.894644Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"dataset = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\nprint(dataset.data.shape)\nprint(dataset.data.mean(axis=(0, 1, 2)) / 255)\nprint(dataset.data.std(axis=(0, 1, 2)) / 255)\ntest_dataset = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n\n# Split training dataset into training and validation\ntrain_size = int(0.8 * len(dataset))\nval_size = len(dataset) - train_size\ntrain_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n\n# Create DataLoaders\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T12:18:28.896096Z","iopub.execute_input":"2025-01-13T12:18:28.896285Z","iopub.status.idle":"2025-01-13T12:18:37.971300Z","shell.execute_reply.started":"2025-01-13T12:18:28.896268Z","shell.execute_reply":"2025-01-13T12:18:37.970433Z"}},"outputs":[{"name":"stdout","text":"Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 170498071/170498071 [00:04<00:00, 35210180.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"Extracting ./data/cifar-10-python.tar.gz to ./data\n(50000, 32, 32, 3)\n[0.49139968 0.48215841 0.44653091]\n[0.24703223 0.24348513 0.26158784]\nFiles already downloaded and verified\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"# show_samples(train_loader)\n# show_samples(val_loader)\n# show_samples(test_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T12:18:37.973478Z","iopub.execute_input":"2025-01-13T12:18:37.973730Z","iopub.status.idle":"2025-01-13T12:18:37.976862Z","shell.execute_reply.started":"2025-01-13T12:18:37.973708Z","shell.execute_reply":"2025-01-13T12:18:37.975989Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"target_model = torch.hub.load(\n    \"chenyaofo/pytorch-cifar-models\", \"cifar10_resnet20\", pretrained=True\n).to(device)\ntarget_model.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T12:18:37.978402Z","iopub.execute_input":"2025-01-13T12:18:37.978731Z","iopub.status.idle":"2025-01-13T12:18:39.849029Z","shell.execute_reply.started":"2025-01-13T12:18:37.978705Z","shell.execute_reply":"2025-01-13T12:18:39.848157Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/torch/hub.py:295: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n  warnings.warn(\nDownloading: \"https://github.com/chenyaofo/pytorch-cifar-models/zipball/master\" to /root/.cache/torch/hub/master.zip\nDownloading: \"https://github.com/chenyaofo/pytorch-cifar-models/releases/download/resnet/cifar10_resnet20-4118986f.pt\" to /root/.cache/torch/hub/checkpoints/cifar10_resnet20-4118986f.pt\n100%|██████████| 1.09M/1.09M [00:00<00:00, 35.3MB/s]\n","output_type":"stream"},{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"CifarResNet(\n  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (2): BasicBlock(\n      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (2): BasicBlock(\n      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (2): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=64, out_features=10, bias=True)\n)"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"# # Evaluate accuracy on test set\n\n# correct = 0\n# total = 0\n# with torch.no_grad():\n#     for images, labels in test_loader:\n#         images, labels = images.to(device), labels.to(device)\n#         outputs = target_model(images)\n#         _, predicted = torch.max(outputs.data, 1)\n#         total += labels.size(0)\n#         correct += (predicted == labels).sum().item()\n\n# print(f\"Test Accuracy: {100 * correct / total}%\")\n\n# ##################################################################### #\n\n# # Generate adversarial images using FGSM\n# epsilon = 0.01\n\n# adv_examples = []\n# true_labels = []\n# pred_labels_orig = []\n# pred_labels_adv = []\n\n# target_model.eval()\n# for images, labels in test_loader:\n#     images, labels = images.to(device), labels.to(device)\n\n#     adv_images = fast_gradient_method(target_model, images, epsilon, norm=np.inf)\n#     adv_examples.append((images, adv_images))\n#     true_labels.extend(labels.cpu().numpy())\n    \n#     with torch.no_grad():\n#         orig_preds = target_model(images).argmax(dim=1)\n#         adv_preds = target_model(adv_images).argmax(dim=1)\n#         pred_labels_orig.extend(orig_preds.cpu().numpy())\n#         pred_labels_adv.extend(adv_preds.cpu().numpy())\n\n# success_rate = attack_success_rate(target_model, adv_examples)\n# print(f\"Attack Success Rate: {success_rate * 100:.2f}%\")\n\n# ##################################################################### #\n\n# show_samples(train_loader)\n# show_samples(val_loader)\n# show_samples(test_loader)\n\n# show_adv_images_with_labels(adv_examples, true_labels, pred_labels_orig, pred_labels_adv)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T12:18:39.849832Z","iopub.execute_input":"2025-01-13T12:18:39.850067Z","iopub.status.idle":"2025-01-13T12:18:39.853812Z","shell.execute_reply.started":"2025-01-13T12:18:39.850046Z","shell.execute_reply":"2025-01-13T12:18:39.852995Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"class Generator(nn.Module):\n    def __init__(self):\n        super(Generator, self).__init__()\n        self.encoder = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1),  # 32x32 -> 16x16\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),  # 16x16 -> 8x8\n            nn.BatchNorm2d(128),\n            nn.LeakyReLU(0.2, inplace=True),\n        )\n        self.decoder = nn.Sequential(\n            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),  # 8x8 -> 16x16\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            nn.ConvTranspose2d(64, 3, kernel_size=4, stride=2, padding=1),  # 16x16 -> 32x32\n            nn.Tanh(),\n        )\n\n    def forward(self, x):\n        encoded = self.encoder(x)\n        decoded = self.decoder(encoded)\n        return decoded\n\nclass Discriminator(nn.Module):\n    def __init__(self):\n        super(Discriminator, self).__init__()\n        self.model = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1),  # 32x32 -> 16x16\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),  # 16x16 -> 8x8\n            nn.BatchNorm2d(128),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(128, 1, kernel_size=8),  # 8x8 -> 1x1\n            nn.Sigmoid(),\n        )\n\n    def forward(self, x):\n        return self.model(x).view(-1)\n\ncross_entropy = nn.CrossEntropyLoss()\n\nclass LossFunctions:\n    @staticmethod\n    def adversarial_loss(target_model, x, perturbation):\n        x_adv = x + perturbation\n        adv_predictions = target_model(x_adv)\n        target_labels = torch.argmax(adv_predictions.detach(), dim=1)  # Detach to avoid graph reuse\n        return cross_entropy(adv_predictions, target_labels)\n\n    @staticmethod\n    def gan_loss(discriminator, x, perturbation):\n        real_loss = torch.log(discriminator(x) + 1e-8).mean()\n        fake_loss = torch.log(1 - discriminator(x + perturbation.detach()) + 1e-8).mean()\n        return -(real_loss + fake_loss)\n\n    @staticmethod\n    def hinge_loss(perturbation, c):\n        norm = torch.norm(perturbation.view(perturbation.size(0), -1), p=2, dim=1)\n        hinge = torch.clamp(norm - c, min=0)\n        return hinge.mean()\n\n    @staticmethod\n    def total_loss(discriminator, target_model, alpha, beta, c, x, perturbation):\n        adv_loss = LossFunctions.adversarial_loss(target_model, x, perturbation)\n        gan_loss = LossFunctions.gan_loss(discriminator, x, perturbation)\n        hinge_loss = LossFunctions.hinge_loss(perturbation, c)\n        return adv_loss + alpha * gan_loss + beta * hinge_loss","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T12:18:39.854774Z","iopub.execute_input":"2025-01-13T12:18:39.855062Z","iopub.status.idle":"2025-01-13T12:18:39.872288Z","shell.execute_reply.started":"2025-01-13T12:18:39.855034Z","shell.execute_reply":"2025-01-13T12:18:39.871596Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"def train_gan(\n    generator, discriminator, target_model, train_loader, val_loader,\n    epochs, g_optimizer, d_optimizer, c, alpha, beta, \n    g_scheduler, d_scheduler, patience\n):\n    g_losses, d_losses, g_accuracies = [], [], []\n    val_g_losses, val_d_losses, val_g_accuracies = [], [], []\n    model_accuracies, attack_success_rates = [], []\n    val_model_accuracies, val_attack_success_rates = [], []\n    best_g_loss, best_d_loss = float('inf'), float('inf')\n    epochs_no_improve = 0\n\n    for epoch in range(epochs):\n        correct_adv, correct_benign, total_samples = 0, 0, 0\n        g_loss_epoch, d_loss_epoch = 0.0, 0.0\n\n        tepoch = tqdm(train_loader, unit=\"batch\", desc=f\"Epoch {epoch+1}/{epochs}\", ncols=100, leave=False)\n        for batch_idx, (images, labels) in enumerate(tepoch):\n            images, labels = images.to(device), labels.to(device)\n            generator.train()\n            discriminator.train()\n            target_model.eval()\n\n            perturbations = generator(images)\n            adv_images = torch.clamp(images + perturbations, -1, 1)\n\n            d_optimizer.zero_grad()\n            d_loss = LossFunctions.gan_loss(discriminator, images, perturbations)\n            d_loss.backward()\n            d_optimizer.step()\n\n            g_optimizer.zero_grad()\n            g_loss = LossFunctions.total_loss(\n                discriminator, target_model,\n                alpha, beta, c, images, perturbations\n            )\n            g_loss.backward()\n            g_optimizer.step()\n\n            g_loss_epoch += g_loss.item()\n            d_loss_epoch += d_loss.item()\n\n            with torch.no_grad():\n                benign_output = target_model(images)\n                _, benign_predicted = benign_output.max(1)\n                adv_output = target_model(adv_images)\n                _, adv_predicted = adv_output.max(1)\n\n                correct_benign += (benign_predicted == labels).sum().item()\n                correct_adv += (adv_predicted != benign_predicted).sum().item()\n                total_samples += labels.size(0)\n\n            tepoch.set_postfix({'Batch': batch_idx + 1, 'G_Loss': g_loss.item(), 'D_Loss': d_loss.item()})\n\n        g_losses.append(g_loss_epoch / len(train_loader))\n        d_losses.append(d_loss_epoch / len(train_loader))\n        g_accuracies.append(correct_adv / total_samples)\n        model_accuracies.append(correct_benign / total_samples)\n        attack_success_rates.append(correct_adv / total_samples)\n\n        generator.eval()\n        discriminator.eval()\n        target_model.eval()\n        val_g_loss_epoch, val_d_loss_epoch = 0.0, 0.0\n        val_correct_adv, val_correct_benign, val_samples = 0, 0, 0\n        with torch.no_grad():\n            for val_images, val_labels in val_loader:\n                val_images, val_labels = val_images.to(device), val_labels.to(device)\n\n                val_perturbations = generator(val_images)\n                # val_perturbations = torch.clamp(generator(val_images), -c, c)\n                val_adv_images = torch.clamp(val_images + val_perturbations, -1, 1)\n\n                val_d_loss = LossFunctions.gan_loss(discriminator, val_images, val_perturbations)\n                val_g_loss = LossFunctions.total_loss(\n                    discriminator, target_model,\n                    alpha, beta, c, val_images, val_perturbations\n                )\n\n                val_g_loss_epoch += val_g_loss.item()\n                val_d_loss_epoch += val_d_loss.item()\n\n                val_benign_output = target_model(val_images)\n                _, val_benign_predicted = val_benign_output.max(1)\n                val_adv_output = target_model(val_adv_images)\n                _, val_adv_predicted = val_adv_output.max(1)\n\n                val_correct_benign += (val_benign_predicted == val_labels).sum().item()\n                val_correct_adv += (val_adv_predicted != val_benign_predicted).sum().item()\n                # val_correct_adv += (val_adv_predicted != val_labels).sum().item()\n                val_samples += val_labels.size(0)\n\n        val_g_losses.append(val_g_loss_epoch / len(val_loader))\n        val_d_losses.append(val_d_loss_epoch / len(val_loader))\n        val_g_accuracies.append(val_correct_adv / val_samples)\n        val_model_accuracies.append(val_correct_benign / val_samples)\n        val_attack_success_rates.append(val_correct_adv / val_samples)\n\n        g_scheduler.step()\n        d_scheduler.step()\n\n        print(f\"Epoch [{epoch+1}/{epochs}], \"\n              f\"Train G_Loss: {g_losses[-1]:.4f}, D_Loss: {d_losses[-1]:.4f}, Model Accuracy: {model_accuracies[-1]:.4f}, \"\n              f\"Attack Success Rate: {attack_success_rates[-1]:.4f}, \"\n              f\"Val G_Loss: {val_g_losses[-1]:.4f}, Val D_Loss: {val_d_losses[-1]:.4f}, \"\n              f\"Val Model Accuracy: {val_model_accuracies[-1]:.4f}, Val Attack Success Rate: {val_attack_success_rates[-1]:.4f}\")\n        if val_g_losses[-1] < best_g_loss or val_d_losses[-1] < best_d_loss:\n            best_g_loss = min(val_g_losses[-1], best_g_loss)\n            best_d_loss = min(val_d_losses[-1], best_d_loss)\n            epochs_no_improve = 0\n        else:\n            epochs_no_improve += 1\n            print(f\"Epochs without improvement: {epochs_no_improve}/{patience}\")\n            if epochs_no_improve >= patience:\n                print(f\"Early stopping triggered after {epoch + 1} epochs.\")\n                break\n    return (g_losses, d_losses, g_accuracies, model_accuracies, attack_success_rates,\n            val_g_losses, val_d_losses, val_g_accuracies, val_model_accuracies, val_attack_success_rates)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T12:18:39.873055Z","iopub.execute_input":"2025-01-13T12:18:39.873326Z","iopub.status.idle":"2025-01-13T12:18:39.892312Z","shell.execute_reply.started":"2025-01-13T12:18:39.873299Z","shell.execute_reply":"2025-01-13T12:18:39.891639Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"generator = Generator().to(device)\ndiscriminator = Discriminator().to(device)\n\nepochs = 50 \nlr = 0.001\nalpha = 1.0 # param alpha: Weight for adversarial loss (LGAN) \nbeta = 10.0 # param beta: Weight for hinge loss (Lhinge)\nc = 8/255   # param c: Hinge loss bound\npatience = 15\n\ng_optimizer = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\nd_optimizer = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n\ng_scheduler = StepLR(g_optimizer, step_size=10, gamma=0.5)\nd_scheduler = StepLR(d_optimizer, step_size=10, gamma=0.5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T12:18:39.892934Z","iopub.execute_input":"2025-01-13T12:18:39.893118Z","iopub.status.idle":"2025-01-13T12:18:39.917224Z","shell.execute_reply.started":"2025-01-13T12:18:39.893103Z","shell.execute_reply":"2025-01-13T12:18:39.916429Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"(g_losses, d_losses, g_accuracies, model_accuracies, attack_success_rates, \n val_g_losses, val_d_losses, val_g_accuracies, val_model_accuracies, \n val_attack_success_rates) = train_gan(\n    generator, discriminator, target_model, train_loader, val_loader,\n    epochs, g_optimizer, d_optimizer, c, alpha, beta, \n    g_scheduler, d_scheduler, patience\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-13T12:18:39.917945Z","iopub.execute_input":"2025-01-13T12:18:39.918163Z","execution_failed":"2025-01-13T12:19:26.507Z"}},"outputs":[{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Epoch [1/50], Train G_Loss: 31.3350, D_Loss: 1.1881, Model Accuracy: 0.9982, Attack Success Rate: 0.1161, Val G_Loss: 17.3526, Val D_Loss: 1.1517, Val Model Accuracy: 0.9974, Val Attack Success Rate: 0.0930\n","output_type":"stream"},{"name":"stderr","text":"Epoch 2/50:  75%|██████  | 236/313 [00:18<00:05, 13.02batch/s, Batch=238, G_Loss=12.7, D_Loss=0.428]","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"plot_losses(\n    epochs, g_losses, d_losses, g_accuracies, model_accuracies, \n    attack_success_rates, val_g_losses, val_d_losses, \n    val_g_accuracies, val_model_accuracies, val_attack_success_rates\n)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-13T12:19:26.508Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"overall_rate, per_class_rate = calculate_attack_success(target_model, test_loader, generator)\n\nprint(f\"Overall Attack Success Rate: {overall_rate * 100:.2f}%\")\nfor i, class_name in enumerate(CLASSES):\n    print(f\"Class {class_name}: {per_class_rate[i] * 100:.2f}%\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-13T12:19:26.508Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"visualize_adversarial_samples(generator, test_loader)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-13T12:19:26.508Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_confidence_histograms(target_model, test_loader, generator)","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-13T12:19:26.508Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# def train_gan(\n#     generator, discriminator, target_model, train_loader, \n#     epochs, g_optimizer, d_optimizer, c, alpha, beta, \n#     g_scheduler, d_scheduler, patience\n# ):\n#     g_losses, d_losses, g_accuracies = [], [], []\n#     best_g_loss, best_d_loss = float('inf'), float('inf')\n#     epochs_no_improve = 0\n\n#     for epoch in range(epochs):\n#         correct_adv = 0\n#         g_loss_epoch, d_loss_epoch = 0.0, 0.0\n#         tepoch = tqdm(train_loader, unit=\"batch\", desc=f\"Epoch {epoch+1}/{epochs}\", ncols=100, leave=False)\n\n#         generator.train()\n#         discriminator.train()\n#         for batch_idx, (images, labels) in enumerate(tepoch):\n#             images, labels = images.to(device), labels.to(device)\n\n#             perturbations = generator(images)\n#             adv_images = torch.clamp(images + perturbations, -1, 1)\n\n#             d_optimizer.zero_grad()\n#             d_loss = LossFunctions.gan_loss(\n#                 discriminator, images, perturbations\n#             )\n#             d_loss.backward()\n#             d_optimizer.step()\n\n#             g_optimizer.zero_grad()\n#             g_loss = LossFunctions.total_loss(\n#                 discriminator, target_model, \n#                 alpha, beta, c, images, perturbations\n#             )\n#             g_loss.backward()\n#             g_optimizer.step()\n\n#             g_loss_epoch += g_loss.item()\n#             d_loss_epoch += d_loss.item()\n#             adv_output = target_model(adv_images)\n#             _, predicted = adv_output.max(1)\n#             correct_adv += (predicted != labels).sum().item()\n#             tepoch.set_postfix({'Batch': batch_idx + 1, 'G_Loss': g_loss.item(), 'D_Loss': d_loss.item()})\n\n#         g_losses.append(g_loss_epoch / len(train_loader))\n#         d_losses.append(d_loss_epoch / len(train_loader))\n#         g_accuracies.append(correct_adv / len(train_loader))\n        \n#         print(f\"Epoch [{epoch+1}/{epochs}], Generator Loss: {g_losses[-1]:.4f}, Discriminator Loss: {d_losses[-1]:.4f}, Fooling Accuracy: {g_accuracies[-1]:.4f}\")\n#         generator.eval()\n#         g_scheduler.step()\n        \n#         discriminator.eval()\n#         d_scheduler.step()\n\n#         if g_losses[-1] < best_g_loss or d_losses[-1] < best_d_loss:\n#             best_g_loss = min(g_losses[-1], best_g_loss)\n#             best_d_loss = min(d_losses[-1], best_d_loss)\n#             epochs_no_improve = 0\n#         else:\n#             print(f\"Epochs without improvement: {epochs_no_improve + 1}/{patience}\")\n#             epochs_no_improve += 1\n#             if epochs_no_improve >= patience:\n#                 print(f\"Early stopping triggered after {epoch + 1} epochs.\")\n#                 break\n\n#     return g_losses, d_losses, g_accuracies\n\n# g_losses, d_losses, g_accuracies = train_gan(\n#     generator, discriminator, target_model, train_loader, \n#     epochs, g_optimizer, d_optimizer, c, alpha, beta, \n#     g_scheduler, d_scheduler, patience\n# )\n\n# plot_losses(epochs, g_losses, d_losses, g_accuracies)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# target_class = 0  # Example: Force adversarial images to be classified as \"airplane\" (class 0)\n# fooling_loss = adv_loss_fn(adv_output, torch.full_like(labels, target_class))\n\n# generator = Generator().to(device)\n# discriminator = Discriminator().to(device)\n\n# epochs = 50 \n# lr = 0.001\n# alpha = 1.0  # Weight for GAN loss\n# beta = 10.0  # Weight for hinge loss\n# # c = 0.1  # Perturbation bound\n# c = 8/255 # Perturbation bound (c) = 8/255 for CIFAR-10\n\n# g_optimizer = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n# d_optimizer = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n\n# g_scheduler = StepLR(g_optimizer, step_size=10, gamma=0.5)\n# d_scheduler = StepLR(d_optimizer, step_size=10, gamma=0.5)\n\n# g_losses, d_losses, g_accuracies = train_gan(\n#     generator, discriminator, target_model, train_loader, \n#     epochs, g_optimizer, d_optimizer, c, alpha, beta, \n#     g_scheduler, d_scheduler, patience\n# )\n\n# plot_losses(epochs, g_losses, d_losses, g_accuracies)\n# overall_rate, per_class_rate = calculate_targeted_attack_success(target_model, test_loader, generator, target_class)\n\n# print(f\"Overall Targeted Attack Success Rate: {overall_rate * 100:.2f}%\")\n# for i, class_name in enumerate(CLASSES):\n#     print(f\"Class {class_name}: {per_class_rate[i] * 100:.2f}%\")\n\n# visualize_adversarial_samples(generator, test_loader)\n# plot_confidence_histograms(target_model, test_loader, generator)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}