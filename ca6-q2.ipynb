{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2094438,"sourceType":"datasetVersion","datasetId":1255979}],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from IPython.display import clear_output\n!pip install cleverhans\nclear_output()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T12:37:23.352454Z","iopub.execute_input":"2025-01-15T12:37:23.352665Z","iopub.status.idle":"2025-01-15T12:37:26.560444Z","shell.execute_reply.started":"2025-01-15T12:37:23.352641Z","shell.execute_reply":"2025-01-15T12:37:26.559449Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import numpy as np\nfrom tqdm import tqdm\nimport pandas as pd\n\nimport torch\nimport torchvision\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport matplotlib.pyplot as plt\nfrom torchvision.utils import make_grid\nfrom torchvision import datasets, transforms\nfrom torch.utils.data import DataLoader, random_split\n\nfrom cleverhans.torch.attacks.fast_gradient_method import fast_gradient_method\nfrom torch.optim.lr_scheduler import StepLR\n\nimport torchvision.transforms as transforms\nimport torchvision.datasets as datasets\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T12:37:26.563380Z","iopub.execute_input":"2025-01-15T12:37:26.563611Z","iopub.status.idle":"2025-01-15T12:37:26.572990Z","shell.execute_reply.started":"2025-01-15T12:37:26.563593Z","shell.execute_reply":"2025-01-15T12:37:26.572247Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"train_transform = transforms.Compose([transforms.ToTensor()])\n\ntrain_set = datasets.CIFAR10(root='../data/', train=True, download=True, transform=train_transform)\nprint(train_set.data.shape)\nprint(train_set.data.mean(axis=(0, 1, 2)) / 255)\nprint(train_set.data.std(axis=(0, 1, 2)) / 255)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T12:37:26.573973Z","iopub.execute_input":"2025-01-15T12:37:26.574199Z","iopub.status.idle":"2025-01-15T12:37:28.356307Z","shell.execute_reply.started":"2025-01-15T12:37:26.574168Z","shell.execute_reply":"2025-01-15T12:37:28.355436Z"}},"outputs":[{"name":"stdout","text":"Files already downloaded and verified\n(50000, 32, 32, 3)\n[0.49139968 0.48215841 0.44653091]\n[0.24703223 0.24348513 0.26158784]\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"batch_size = 128\nmean       = [0.49139968, 0.48215841, 0.44653091]\nstd        = [0.24703223, 0.24348513, 0.26158784]\n\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize(mean, std)\n])\n\nCLASSES = [\n    'airplane', 'automobile', 'bird', 'cat', 'deer',\n    'dog', 'frog', 'horse', 'ship', 'truck'\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T12:37:28.359262Z","iopub.execute_input":"2025-01-15T12:37:28.359491Z","iopub.status.idle":"2025-01-15T12:37:28.364236Z","shell.execute_reply.started":"2025-01-15T12:37:28.359471Z","shell.execute_reply":"2025-01-15T12:37:28.363395Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def denormalize(img, mean, std):\n    img = img.numpy().transpose((1, 2, 0))\n    img = img * std + mean\n    return np.clip(img, 0, 1)\n\ndef show_samples(data_loader):\n    data_iter = iter(data_loader)\n    images, labels = next(data_iter)\n    images = images[:5]\n    labels = labels[:5]\n    fig, axes = plt.subplots(1, 5, figsize=(15, 3))\n    for i, ax in enumerate(axes):\n        img = denormalize(images[i], mean, std)\n        ax.imshow(img)\n        ax.set_title(f\"{CLASSES[labels[i].item()]}\", fontsize=20)\n        ax.axis(\"off\")\n    plt.show()\n\ndef show_adv_images_with_labels(adv_examples, true_labels, pred_labels_orig, pred_labels_adv):\n    orig_images, adv_images = adv_examples[0]  # Example batch\n    fig, axes = plt.subplots(3, 5, figsize=(15, 8))\n    for i in range(5):\n        orig = denormalize(orig_images[i].detach().cpu(), mean, std)\n        adv = denormalize(adv_images[i].detach().cpu(), mean, std)\n        diff = np.abs(adv - orig)\n\n        true_label = CLASSES[true_labels[i]]\n        orig_pred_label = CLASSES[pred_labels_orig[i]]\n        adv_pred_label = CLASSES[pred_labels_adv[i]]\n\n        axes[0, i].imshow(orig)\n        axes[0, i].set_title(f\"True: {true_label}\\nPred: {orig_pred_label}\")\n        axes[0, i].axis(\"off\")\n        axes[1, i].imshow(adv)\n        axes[1, i].set_title(f\"Adversarial\\nPred: {adv_pred_label}\")\n        axes[1, i].axis(\"off\")\n        axes[2, i].imshow(diff)\n        axes[2, i].set_title(\"Difference\")\n        axes[2, i].axis(\"off\")\n    plt.tight_layout()\n    plt.show()\n\ndef visualize_adversarial_samples(generator, test_loader):\n    generator.eval()\n\n    images, labels = next(iter(test_loader))\n    images, labels = images[:5].to(device), labels[:5].to(device)\n    with torch.no_grad():\n        perturbations = generator(images)\n        adv_images = torch.clamp(images + perturbations, -1, 1)\n\n    images = images.cpu()\n    adv_images = adv_images.cpu()\n    perturbations = perturbations.cpu()\n\n    fig, axes = plt.subplots(3, 5, figsize=(15, 8))\n    for i in range(5):\n        axes[0, i].imshow(denormalize(images[i], mean, std))\n        axes[0, i].set_title(f\"Original: {CLASSES[labels[i]]}\")\n        axes[0, i].axis(\"off\")\n        axes[1, i].imshow(denormalize(adv_images[i], mean, std))\n        axes[1, i].set_title(\"Adversarial\")\n        axes[1, i].axis(\"off\")\n        axes[2, i].imshow(denormalize(perturbations[i], mean, std), cmap=\"seismic\")\n        axes[2, i].set_title(\"Perturbation\")\n        axes[2, i].axis(\"off\")\n    plt.tight_layout()\n    plt.show()\n\ndef plot_losses(epochs, g_losses, d_losses, attack_success_rates, val_g_losses, val_d_losses, val_attack_success_rates):\n# val_g_accuracies, val_model_accuracies, g_accuracies, model_accuracies, \n    actual_epochs = len(g_losses)    \n    plt.figure(figsize=(18, 10))\n    plt.subplot(2, 3, 1)\n    plt.plot(range(1, actual_epochs + 1), g_losses, label='Generator Loss', color='blue')\n    plt.plot(range(1, actual_epochs + 1), d_losses, label='Discriminator Loss', color='red')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.title('Generator and Discriminator Losses')\n    plt.legend()\n    plt.subplot(2, 3, 2)\n    plt.plot(range(1, actual_epochs + 1), attack_success_rates, label='Attack Success Rate', color='orange')\n    plt.plot(range(1, actual_epochs + 1), val_attack_success_rates, label='Validation Attack Success Rate', color='green')\n    plt.xlabel('Epochs')\n    plt.ylabel('Success Rate')\n    plt.title('Attack Success Rates')\n    plt.legend()\n    plt.subplot(2, 3, 3)\n    plt.plot(range(1, actual_epochs + 1), val_g_losses, label='Validation Generator Loss', color='blue')\n    plt.plot(range(1, actual_epochs + 1), val_d_losses, label='Validation Discriminator Loss', color='red')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.title('Validation Generator and Discriminator Losses')\n    plt.legend()\n    plt.tight_layout()\n    plt.show()\n\ndef plot_confidence_histograms(target_model, test_loader, generator):\n    normal_confidences = []\n    adversarial_confidences = []\n\n    generator.eval()\n    target_model.eval()\n    with torch.no_grad():\n        for images, labels in test_loader:\n            images, labels = images.to(device), labels.to(device)\n            perturbations = generator(images)\n            adv_images = torch.clamp(images + perturbations, -1, 1)\n            # Get softmax confidence for normal and adversarial images\n            normal_outputs = torch.softmax(target_model(images), dim=1)\n            adv_outputs = torch.softmax(target_model(adv_images), dim=1)\n\n            normal_confidences.extend(normal_outputs.max(1)[0].cpu().numpy())\n            adversarial_confidences.extend(adv_outputs.max(1)[0].cpu().numpy())\n    plt.figure(figsize=(10, 5))\n    plt.hist(adversarial_confidences, bins=20, alpha=0.7, label=\"Adversarial Samples\", color=\"red\")\n    plt.hist(normal_confidences, bins=20, alpha=0.7, label=\"Normal Samples\", color=\"blue\")\n    plt.xlabel(\"Confidence\")\n    plt.ylabel(\"Frequency\")\n    plt.title(\"Confidence Histogram: Normal vs Adversarial\")\n    plt.legend()\n    plt.show()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T12:37:28.365019Z","iopub.execute_input":"2025-01-15T12:37:28.365212Z","iopub.status.idle":"2025-01-15T12:37:28.386897Z","shell.execute_reply.started":"2025-01-15T12:37:28.365195Z","shell.execute_reply":"2025-01-15T12:37:28.386260Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def attack_success_rate(model, adv_examples):\n    total, success = 0, 0\n    model.eval()\n    for orig_images, adv_images in adv_examples:\n        with torch.no_grad():\n            orig_preds = model(orig_images).argmax(dim=1)\n            adv_preds = model(adv_images).argmax(dim=1)\n            success += (orig_preds != adv_preds).sum().item()\n            total += orig_images.size(0)\n    return success / total\n\ndef calculate_attack_success(target_model, test_loader, generator):\n    overall_success = 0\n    per_class_success = np.zeros(10)\n    per_class_count = np.zeros(10)\n\n    generator.eval()\n    target_model.eval()\n    with torch.no_grad():\n        for images, labels in test_loader:\n            images, labels = images.to(device), labels.to(device)\n            perturbations = generator(images)\n            adv_images = torch.clamp(images + perturbations, -1, 1)\n            # Get predictions on adversarial samples\n            adv_outputs = target_model(adv_images)\n            _, adv_preds = adv_outputs.max(1)\n            fooled = (adv_preds != labels).cpu().numpy()\n            overall_success += fooled.sum()\n            for label, is_fooled in zip(labels.cpu().numpy(), fooled):\n                per_class_count[label] += 1\n                per_class_success[label] += is_fooled\n    overall_rate = overall_success / sum(per_class_count)\n    per_class_rate = per_class_success / per_class_count\n    return overall_rate, per_class_rate\n\ndef calculate_targeted_attack_success(target_model, test_loader, generator, target_class):\n    overall_success = 0\n    per_class_success = np.zeros(10)\n    per_class_count = np.zeros(10)\n\n    generator.eval()\n    target_model.eval()\n\n    with torch.no_grad():\n        for images, labels in test_loader:\n            images, labels = images.to(device), labels.to(device)\n            perturbations = generator(images)\n            adv_images = torch.clamp(images + perturbations, -1, 1)\n\n            # Get predictions on adversarial samples\n            adv_outputs = target_model(adv_images)\n            _, adv_preds = adv_outputs.max(1)\n\n            # Check if target model was successfully targeted\n            targeted = (adv_preds == target_class).cpu().numpy()\n            overall_success += targeted.sum()\n\n            # Update per-class metrics\n            for label, is_targeted in zip(labels.cpu().numpy(), targeted):\n                per_class_count[label] += 1\n                per_class_success[label] += is_targeted\n\n    overall_rate = overall_success / sum(per_class_count)\n    per_class_rate = per_class_success / per_class_count\n\n    return overall_rate, per_class_rate","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T12:37:28.387699Z","iopub.execute_input":"2025-01-15T12:37:28.387955Z","iopub.status.idle":"2025-01-15T12:37:28.406900Z","shell.execute_reply.started":"2025-01-15T12:37:28.387935Z","shell.execute_reply":"2025-01-15T12:37:28.406203Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"dataset = datasets.CIFAR10(root=\"./data\", train=True, download=True, transform=transform)\nprint(dataset.data.shape)\nprint(dataset.data.mean(axis=(0, 1, 2)) / 255)\nprint(dataset.data.std(axis=(0, 1, 2)) / 255)\ntest_dataset = datasets.CIFAR10(root=\"./data\", train=False, download=True, transform=transform)\n\n# Split training dataset into training and validation\ntrain_size = int(0.8 * len(dataset))\nval_size = len(dataset) - train_size\ntrain_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n\n# Create DataLoaders\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader   = DataLoader(val_dataset,   batch_size=batch_size, shuffle=False)\ntest_loader  = DataLoader(test_dataset,  batch_size=batch_size, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T12:37:28.407722Z","iopub.execute_input":"2025-01-15T12:37:28.407985Z","iopub.status.idle":"2025-01-15T12:37:30.863607Z","shell.execute_reply.started":"2025-01-15T12:37:28.407951Z","shell.execute_reply":"2025-01-15T12:37:30.862803Z"}},"outputs":[{"name":"stdout","text":"Files already downloaded and verified\n(50000, 32, 32, 3)\n[0.49139968 0.48215841 0.44653091]\n[0.24703223 0.24348513 0.26158784]\nFiles already downloaded and verified\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"# show_samples(train_loader)\n# show_samples(val_loader)\n# show_samples(test_loader)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T12:37:30.864472Z","iopub.execute_input":"2025-01-15T12:37:30.864703Z","iopub.status.idle":"2025-01-15T12:37:30.868091Z","shell.execute_reply.started":"2025-01-15T12:37:30.864683Z","shell.execute_reply":"2025-01-15T12:37:30.867165Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"target_model = torch.hub.load(\n    \"chenyaofo/pytorch-cifar-models\", \"cifar10_resnet20\", pretrained=True\n).to(device)\ntarget_model.eval()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T12:37:30.868945Z","iopub.execute_input":"2025-01-15T12:37:30.869208Z","iopub.status.idle":"2025-01-15T12:37:31.296969Z","shell.execute_reply.started":"2025-01-15T12:37:30.869180Z","shell.execute_reply":"2025-01-15T12:37:31.295949Z"}},"outputs":[{"name":"stderr","text":"Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n","output_type":"stream"},{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"CifarResNet(\n  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (2): BasicBlock(\n      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (2): BasicBlock(\n      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (2): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=64, out_features=10, bias=True)\n)"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"# # Evaluate accuracy on test set\n# correct = 0\n# total = 0\n# with torch.no_grad():\n#     for images, labels in test_loader:\n#         images, labels = images.to(device), labels.to(device)\n#         outputs = target_model(images)\n#         _, predicted = torch.max(outputs.data, 1)\n#         total += labels.size(0)\n#         correct += (predicted == labels).sum().item()\n# print(f\"Test Accuracy: {100 * correct / total}%\")\n\n# ## ................................................ ##\n\n# # Generate adversarial images using FGSM\n# epsilon = 0.01\n\n# adv_examples = []\n# true_labels = []\n# pred_labels_orig = []\n# pred_labels_adv = []\n\n# target_model.eval()\n# for images, labels in test_loader:\n#     images, labels = images.to(device), labels.to(device)\n\n#     adv_images = fast_gradient_method(target_model, images, epsilon, norm=np.inf)\n#     adv_examples.append((images, adv_images))\n#     true_labels.extend(labels.cpu().numpy())\n    \n#     with torch.no_grad():\n#         orig_preds = target_model(images).argmax(dim=1)\n#         adv_preds = target_model(adv_images).argmax(dim=1)\n#         pred_labels_orig.extend(orig_preds.cpu().numpy())\n#         pred_labels_adv.extend(adv_preds.cpu().numpy())\n\n# success_rate = attack_success_rate(target_model, adv_examples)\n# print(f\"Attack Success Rate: {success_rate * 100:.2f}%\")\n\n# ## ................................................ ##\n\n# show_samples(train_loader)\n# show_samples(val_loader)\n# show_samples(test_loader)\n\n# show_adv_images_with_labels(adv_examples, true_labels, pred_labels_orig, pred_labels_adv)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T12:37:31.298065Z","iopub.execute_input":"2025-01-15T12:37:31.298335Z","iopub.status.idle":"2025-01-15T12:37:31.303194Z","shell.execute_reply.started":"2025-01-15T12:37:31.298289Z","shell.execute_reply":"2025-01-15T12:37:31.302254Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class Generator(nn.Module):\n    def __init__(self):\n        super(Generator, self).__init__()\n        self.encoder = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1),  # 32x32 -> 16x16\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1),  # 16x16 -> 8x8\n            nn.BatchNorm2d(128),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1),  # 8x8 -> 4x4\n            nn.BatchNorm2d(256),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(256, 512, kernel_size=3, stride=2, padding=1),  # 4x4 -> 2x2\n            nn.BatchNorm2d(512)\n        )\n        self.decoder = nn.Sequential(\n            nn.ReLU(True),\n            nn.ConvTranspose2d(512, 256, kernel_size=3, stride=2, padding=1, output_padding=1),  # 2x2 -> 4x4\n            nn.BatchNorm2d(256),\n            nn.Dropout(0.5),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1),  # 4x4 -> 8x8\n            nn.BatchNorm2d(128),\n            nn.Dropout(0.5),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1),  # 8x8 -> 16x16\n            nn.BatchNorm2d(64),\n            nn.ReLU(True),\n            nn.ConvTranspose2d(64, 3, kernel_size=3, stride=2, padding=1, output_padding=1),  # 16x16 -> 32x32\n            nn.Tanh()\n        )\n    \n    def forward(self, x):\n        encoded = self.encoder(x)\n        decoded = self.decoder(encoded)\n        return decoded\n\nclass Discriminator(nn.Module):\n    def __init__(self):\n        super(Discriminator, self).__init__()\n        self.model = nn.Sequential(\n            nn.Conv2d(3, 8, kernel_size=4, stride=2, padding=1),  # 32x32 -> 16x16\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(8, 16, kernel_size=4, stride=2, padding=1),  # 16x16 -> 8x8\n            nn.BatchNorm2d(16),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(16, 32, kernel_size=4, stride=2, padding=1),  # 8x8 -> 4x4\n            nn.BatchNorm2d(32),\n            nn.LeakyReLU(0.2, inplace=True),\n            nn.Conv2d(32, 1, kernel_size=4),  # 4x4 -> 1x1\n            nn.Sigmoid()  # Normalize output to [0, 1]\n            # nn.Flatten(),  # Flatten the feature map: 4x4x32 -> 512\n            # nn.Linear(4 * 4 * 32, 1)  # Linear layer for final output\n        )\n    def forward(self, x):\n        return self.model(x).view(-1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T12:37:31.305713Z","iopub.execute_input":"2025-01-15T12:37:31.306062Z","iopub.status.idle":"2025-01-15T12:37:31.326221Z","shell.execute_reply.started":"2025-01-15T12:37:31.306028Z","shell.execute_reply":"2025-01-15T12:37:31.325133Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# def gan_loss(discriminator, original_images, perturbations):\n#     mse_loss = nn.MSELoss()\n#     real_preds = discriminator(original_images)\n#     real_targets = torch.ones_like(real_preds)  # Targets for real images are 1\n#     real_loss = mse_loss(real_preds, real_targets)\n#     fake_images = original_images + perturbations\n#     fake_preds = discriminator(fake_images)\n#     fake_targets = torch.zeros_like(fake_preds)  # Targets for fake images are 0\n#     fake_loss = mse_loss(fake_preds, fake_targets)\n#     total_gan_loss = real_loss + fake_loss\n#     return total_gan_loss\n# def adversarial_loss(target_model, adv_images, target_labels):\n#     outputs = target_model(adv_images)\n#     return F.cross_entropy(outputs, target_labels)\n# def hinge_loss(perturbations, c):\n#     norm = torch.norm(perturbations.view(perturbations.size(0), -1), dim=1)  # L2 norm\n#     hinge = F.relu(norm - c)\n#     return torch.mean(hinge)\n\nclass LossFunctions:\n    @staticmethod\n    def gan_loss():\n        return nn.MSELoss()\n\n    @staticmethod\n    def adv_loss(logits, target, num_classes=10, kappa=0):\n        target_one_hot = torch.eye(num_classes).type(logits.type())[target.long()]\n        real = torch.sum(target_one_hot * logits, 1)\n        other = torch.max((1 - target_one_hot) * logits - (target_one_hot * 10000), 1)[0]\n        kappa = torch.zeros_like(other).fill_(kappa)\n        return torch.sum(torch.max(real - other, kappa))\n\n    @staticmethod\n    def hinge_loss(perturb, c):\n        norm = torch.norm(perturb.view(perturb.size(0), -1), dim=1)\n        clamped = torch.clamp(norm - c, min=0)\n        return torch.mean(clamped)\n\n    @staticmethod\n    def total_loss(adv_loss_value, gan_loss_value, hinge_loss_value, alpha, beta):\n        return alpha * gan_loss_value + beta * hinge_loss_value + adv_loss_value\n\n    @staticmethod\n    def total_gan_loss(real_loss, fake_loss):\n        return real_loss + fake_loss\n        real_loss = LossFunctions.gan_loss()(D(images), torch.ones(batch_size, device=device))\n        fake_loss = LossFunctions.gan_loss()(D(adversarial_images.detach()), torch.zeros(batch_size, device=device))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T12:37:31.327555Z","iopub.execute_input":"2025-01-15T12:37:31.327901Z","iopub.status.idle":"2025-01-15T12:37:31.346270Z","shell.execute_reply.started":"2025-01-15T12:37:31.327851Z","shell.execute_reply":"2025-01-15T12:37:31.345353Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"def attack_success(model, adversarial_images, labels):\n    with torch.no_grad():\n        adv_preds = model(adversarial_images).argmax(dim=1)\n        success = (labels != adv_preds).sum().item()\n    return success\n\ndef train_epoch(epoch, G, D, train_loader, optimizer_G, optimizer_D, target_model, alpha, beta, epochs):\n    G.train(), D.train()\n    train_g_loss, train_d_loss, train_attack_success_counts = 0, 0, 0\n    tepoch = tqdm(train_loader, unit=\"batch\", desc=f\"Training Epoch {epoch+1}/{epochs}\", ncols=100, leave=False)\n    for batch_idx, (images, labels) in enumerate(tepoch):\n        images, labels = images.to(device), labels.to(device)\n        batch_size = images.size(0)\n        perturbations = G(images)\n        adversarial_images = images + perturbations\n\n        optimizer_D.zero_grad()\n        d_loss = LossFunctions.total_gan_loss(\n            real_loss=LossFunctions.gan_loss()(D(images), torch.ones(batch_size, device=device)), \n            fake_loss=LossFunctions.gan_loss()(D(adversarial_images.detach()), torch.zeros(batch_size, device=device))\n        )\n        d_loss.backward()\n        optimizer_D.step()\n\n        optimizer_G.zero_grad()\n        g_loss = LossFunctions.total_loss(\n            adv_loss_value=LossFunctions.adv_loss(target_model(adversarial_images), labels),\n            gan_loss_value=LossFunctions.gan_loss()(D(adversarial_images), torch.ones(batch_size, device=device)), \n            hinge_loss_value=LossFunctions.hinge_loss(perturbations, c), \n            alpha=alpha, beta=beta\n        )\n        g_loss.backward()\n        optimizer_G.step()\n\n        train_g_loss += g_loss.item()\n        train_d_loss += d_loss.item()\n        train_attack_success_counts += attack_success(target_model, adversarial_images, labels)\n        tepoch.set_postfix({'Batch': batch_idx + 1, 'G_Loss': g_loss.item(), 'D_Loss': d_loss.item()})\n    return (train_g_loss/len(train_loader)), (train_d_loss/len(train_loader)), (train_attack_success_counts/len(train_dataset))\n\ndef validate_epoch(G, D, val_loader, target_model, alpha, beta):\n    G.eval(), D.eval()\n    val_g_loss, val_d_loss, val_attack_success_counts = 0, 0, 0\n    with torch.no_grad():\n        for val_images, val_labels in val_loader:\n            val_images, val_labels = val_images.to(device), val_labels.to(device)\n            batch_size = val_images.size(0)\n            val_perturbations = G(val_images)\n            val_adversarial_images = val_images + val_perturbations\n\n            val_d_loss_batch = LossFunctions.total_gan_loss(\n                real_loss = LossFunctions.gan_loss()(D(val_images), torch.ones(batch_size, device=device)),\n                fake_loss = LossFunctions.gan_loss()(D(val_adversarial_images), torch.zeros(batch_size, device=device))\n            )\n            val_g_loss_batch = LossFunctions.total_loss(\n                adv_loss_value=LossFunctions.adv_loss(target_model(val_adversarial_images), val_labels),\n                gan_loss_value=LossFunctions.gan_loss()(D(val_adversarial_images), torch.ones(batch_size, device=device)), \n                hinge_loss_value=LossFunctions.hinge_loss(val_perturbations, c), \n                alpha=alpha, beta=beta\n            )\n            \n            val_g_loss += val_g_loss_batch.item()\n            val_d_loss += val_d_loss_batch.item()\n            val_attack_success_counts += attack_success(target_model, val_adversarial_images, val_labels)\n    return (val_g_loss/len(val_loader)), (val_d_loss/len(val_loader)), (val_attack_success_counts/len(val_dataset))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T12:37:31.346963Z","iopub.execute_input":"2025-01-15T12:37:31.347258Z","iopub.status.idle":"2025-01-15T12:37:31.363589Z","shell.execute_reply.started":"2025-01-15T12:37:31.347223Z","shell.execute_reply":"2025-01-15T12:37:31.362936Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"G = Generator().to(device)\nD = Discriminator().to(device)\n\nepochs = 50 \nlr = 0.001\nalpha = 1.0 # param alpha: Weight for adversarial loss (LGAN) \nbeta = 10.0 # param beta: Weight for hinge loss (Lhinge)\nc = 8/255   # param c: Hinge loss bound\npatience = 12\n8 / (255 * torch.tensor(std).max().item())\noptimizer_G = optim.Adam(G.parameters(), lr=lr, betas=(0.5, 0.999)) # , betas=(0.5, 0.999)\noptimizer_D = optim.Adam(D.parameters(), lr=lr, betas=(0.5, 0.999)) # , betas=(0.5, 0.999)\n\ng_scheduler = StepLR(optimizer_G, step_size=10, gamma=0.5)\nd_scheduler = StepLR(optimizer_D, step_size=10, gamma=0.5)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T12:37:31.364576Z","iopub.execute_input":"2025-01-15T12:37:31.364894Z","iopub.status.idle":"2025-01-15T12:37:31.410139Z","shell.execute_reply.started":"2025-01-15T12:37:31.364841Z","shell.execute_reply":"2025-01-15T12:37:31.409553Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"best_val_loss = float('inf')\npatience_counter = 0\ng_losses, d_losses, g_accuracies = [], [], []\nval_g_losses, val_d_losses = [], []\nattack_success_rates, val_attack_success_rates = [], []\n\nfor epoch in range(epochs):\n    g_loss, d_loss, attack_success_rate = train_epoch(\n        epoch, G, D, train_loader, optimizer_G, optimizer_D, target_model, alpha, beta, epochs\n    )\n    g_losses.append(g_loss)\n    d_losses.append(d_loss)\n    attack_success_rates.append(attack_success_rate)\n    \n    val_g_loss, val_d_loss, val_attack_success_rate = validate_epoch(\n        G, D, val_loader, target_model, alpha, beta\n    )\n    val_g_losses.append(val_g_loss)\n    val_d_losses.append(val_d_loss)\n    val_attack_success_rates.append(val_attack_success_rate)\n    \n    print(f\"Epoch {epoch+1}/{epochs} | g_loss: {g_loss:.4f}, d_loss: {d_loss:.4f}, val_g_loss: {val_g_loss:.4f}, val_d_loss: {val_d_loss:.4f}, attack_success_rate: {attack_success_rate:.4f}, val_attack_success_rate: {val_attack_success_rate:.4f}\")        \n    g_scheduler.step(), d_scheduler.step()\n    print(f\"Learning rate for generator: {g_scheduler.get_last_lr()[0]}, Learning rate for discriminator: {d_scheduler.get_last_lr()[0]}\") \n\n    if val_g_loss < best_val_loss:\n        best_val_loss = val_g_loss\n        patience_counter = 0\n        torch.save(G.state_dict(), 'best_generator.pth')\n        torch.save(D.state_dict(), 'best_discriminator.pth')\n    else:\n        print(f\"Patience counter: {patience_counter + 1}/{patience}\")\n        patience_counter += 1\n    if patience_counter >= patience:\n        print(f\"Early stopping triggered after {epoch + 1} epochs.\")\n        break","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-15T12:37:31.410843Z","iopub.execute_input":"2025-01-15T12:37:31.411099Z","execution_failed":"2025-01-15T12:44:24.255Z"}},"outputs":[{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Epoch 1/50 | g_loss: 169.3494, d_loss: 0.0154, val_g_loss: 127.7969, val_d_loss: 0.2079, attack_success_rate: 0.8641, val_attack_success_rate: 0.8797\nLearning rate for generator: 0.001, Learning rate for discriminator: 0.001\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Epoch 2/50 | g_loss: 129.4487, d_loss: 0.0000, val_g_loss: 118.6016, val_d_loss: 0.1348, attack_success_rate: 0.8860, val_attack_success_rate: 0.8984\nLearning rate for generator: 0.001, Learning rate for discriminator: 0.001\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Epoch 3/50 | g_loss: 118.6614, d_loss: 0.0000, val_g_loss: 110.9631, val_d_loss: 0.2069, attack_success_rate: 0.8967, val_attack_success_rate: 0.8882\nLearning rate for generator: 0.001, Learning rate for discriminator: 0.001\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Epoch 4/50 | g_loss: 112.9163, d_loss: 0.0000, val_g_loss: 111.0995, val_d_loss: 0.4258, attack_success_rate: 0.9020, val_attack_success_rate: 0.8950\nLearning rate for generator: 0.001, Learning rate for discriminator: 0.001\nPatience counter: 1/12\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Epoch 5/50 | g_loss: 108.1064, d_loss: 0.0000, val_g_loss: 104.4267, val_d_loss: 0.5058, attack_success_rate: 0.9091, val_attack_success_rate: 0.9002\nLearning rate for generator: 0.001, Learning rate for discriminator: 0.001\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Epoch 6/50 | g_loss: 106.1960, d_loss: 0.0000, val_g_loss: 102.7951, val_d_loss: 0.5144, attack_success_rate: 0.9112, val_attack_success_rate: 0.9244\nLearning rate for generator: 0.001, Learning rate for discriminator: 0.001\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Epoch 7/50 | g_loss: 103.2523, d_loss: 0.0000, val_g_loss: 107.6912, val_d_loss: 0.5481, attack_success_rate: 0.9121, val_attack_success_rate: 0.9028\nLearning rate for generator: 0.001, Learning rate for discriminator: 0.001\nPatience counter: 1/12\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Epoch 8/50 | g_loss: 100.5570, d_loss: 0.0000, val_g_loss: 98.7040, val_d_loss: 0.4503, attack_success_rate: 0.9167, val_attack_success_rate: 0.9286\nLearning rate for generator: 0.001, Learning rate for discriminator: 0.001\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Epoch 9/50 | g_loss: 98.2213, d_loss: 0.0000, val_g_loss: 100.8930, val_d_loss: 0.4654, attack_success_rate: 0.9198, val_attack_success_rate: 0.8936\nLearning rate for generator: 0.001, Learning rate for discriminator: 0.001\nPatience counter: 1/12\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Epoch 10/50 | g_loss: 97.5302, d_loss: 0.0000, val_g_loss: 100.0644, val_d_loss: 0.4982, attack_success_rate: 0.9218, val_attack_success_rate: 0.9152\nLearning rate for generator: 0.0005, Learning rate for discriminator: 0.0005\nPatience counter: 2/12\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Epoch 11/50 | g_loss: 91.8798, d_loss: 0.0000, val_g_loss: 100.0839, val_d_loss: 0.6150, attack_success_rate: 0.9264, val_attack_success_rate: 0.8870\nLearning rate for generator: 0.0005, Learning rate for discriminator: 0.0005\nPatience counter: 3/12\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Epoch 12/50 | g_loss: 89.0996, d_loss: 0.0000, val_g_loss: 91.8105, val_d_loss: 0.5694, attack_success_rate: 0.9297, val_attack_success_rate: 0.9075\nLearning rate for generator: 0.0005, Learning rate for discriminator: 0.0005\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Epoch 13/50 | g_loss: 87.7193, d_loss: 0.0000, val_g_loss: 94.3415, val_d_loss: 0.6295, attack_success_rate: 0.9332, val_attack_success_rate: 0.9308\nLearning rate for generator: 0.0005, Learning rate for discriminator: 0.0005\nPatience counter: 1/12\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Epoch 14/50 | g_loss: 86.2813, d_loss: 0.0000, val_g_loss: 90.6174, val_d_loss: 0.7004, attack_success_rate: 0.9360, val_attack_success_rate: 0.9338\nLearning rate for generator: 0.0005, Learning rate for discriminator: 0.0005\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Epoch 15/50 | g_loss: 85.0467, d_loss: 0.0000, val_g_loss: 92.9536, val_d_loss: 0.5762, attack_success_rate: 0.9372, val_attack_success_rate: 0.9112\nLearning rate for generator: 0.0005, Learning rate for discriminator: 0.0005\nPatience counter: 1/12\n","output_type":"stream"},{"name":"stderr","text":"                                                                                                    \r","output_type":"stream"},{"name":"stdout","text":"Epoch 16/50 | g_loss: 83.4629, d_loss: 0.0000, val_g_loss: 91.4607, val_d_loss: 0.5922, attack_success_rate: 0.9388, val_attack_success_rate: 0.9103\nLearning rate for generator: 0.0005, Learning rate for discriminator: 0.0005\nPatience counter: 2/12\n","output_type":"stream"},{"name":"stderr","text":"Training Epoch 17/50:  72%|▋| 226/313 [00:15<00:05, 14.60batch/s, Batch=228, G_Loss=85, D_Loss=2.38e","output_type":"stream"}],"execution_count":null},{"cell_type":"code","source":"# best_val_loss = float('inf')\n# patience_counter = 0\n# g_losses, d_losses, g_accuracies = [], [], []\n# val_g_losses, val_d_losses = [], []\n# attack_success_rates, val_attack_success_rates = [], []\n# # g_accuracies, val_g_accuracies = [], []\n# # model_accuracies, val_model_accuracies = [], []\n# for epoch in range(epochs):\n#     g_loss, d_loss, attack_success_rate = train_epoch(\n#         epoch, G, D, train_loader, optimizer_G, optimizer_D, target_model, alpha, beta\n#     )\n#     g_losses.append(g_loss)\n#     d_losses.append(d_loss)\n#     attack_success_rates.append(attack_success_rate)\n    \n#     val_g_loss, val_d_loss, val_attack_success_rate = validate_epoch(\n#         G, D, val_loader, target_model, alpha, beta\n#     )\n#     val_g_losses.append(val_g_loss)\n#     val_d_losses.append(val_d_loss)\n#     val_attack_success_rates.append(val_attack_success_rate)\n    \n#     print(f\"Epoch {epoch+1}/{epochs} | g_loss: {g_loss:.4f}, d_loss: {d_loss:.4f}, val_g_loss: {val_g_loss:.4f}, val_d_loss: {val_d_loss:.4f}, attack_success_rate: {attack_success_rate:.4f}, val_attack_success_rate: {val_attack_success_rate:.4f}\")    \n#     if val_g_loss < best_val_loss:\n#         best_val_loss = val_g_loss\n#         patience_counter = 0\n#         torch.save(G.state_dict(), 'best_generator.pth')\n#         torch.save(D.state_dict(), 'best_discriminator.pth')\n#     else:\n#         print(f\"Patience counter: {patience_counter + 1}/{patience}\")\n#         patience_counter += 1\n\n#     if patience_counter >= patience:\n#         print(f\"Early stopping triggered after {epoch + 1} epochs.\")\n#         print(\"Early stopping triggered.\")\n#         break","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-15T12:44:24.256Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"actual_epochs = len(g_losses)    \nplt.figure(figsize=(18, 10))\n\nplt.subplot(2, 3, 1)\nplt.plot(range(1, actual_epochs + 1), g_losses, label='Generator Loss', color='blue')\nplt.plot(range(1, actual_epochs + 1), d_losses, label='Discriminator Loss', color='red')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('Generator and Discriminator Losses')\nplt.legend()\n\nplt.subplot(2, 3, 2)\nplt.plot(range(1, actual_epochs + 1), attack_success_rates, label='Attack Success Rate', color='orange')\nplt.plot(range(1, actual_epochs + 1), val_attack_success_rates, label='Validation Attack Success Rate', color='green')\nplt.xlabel('Epochs')\nplt.ylabel('Success Rate')\nplt.title('Attack Success Rates')\nplt.legend()\n\nplt.subplot(2, 3, 3)\nplt.plot(range(1, actual_epochs + 1), val_g_losses, label='Validation Generator Loss', color='blue')\nplt.plot(range(1, actual_epochs + 1), val_d_losses, label='Validation Discriminator Loss', color='red')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('Validation Generator and Discriminator Losses')\nplt.legend()\n\nplt.tight_layout()\nplt.show()","metadata":{"trusted":true,"execution":{"execution_failed":"2025-01-15T12:44:24.256Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# def train_gan(\n#     G, D, target_model, train_loader, val_loader,\n#     epochs, optimizer_G, optimizer_D, c, alpha, beta, \n#     g_scheduler, d_scheduler, patience\n# ):\n#     g_losses, d_losses, g_accuracies = [], [], []\n#     val_g_losses, val_d_losses, val_g_accuracies = [], [], []\n#     model_accuracies, attack_success_rates = [], []\n#     val_model_accuracies, val_attack_success_rates = [], []\n#     best_g_loss, best_d_loss = float('inf'), float('inf')\n#     epochs_no_improve = 0\n\n#     for epoch in range(epochs):\n#         correct_adv, correct_benign, total_samples = 0, 0, 0\n#         g_loss_epoch, d_loss_epoch = 0.0, 0.0\n\n#         tepoch = tqdm(train_loader, unit=\"batch\", desc=f\"Epoch {epoch+1}/{epochs}\", ncols=100, leave=False)\n\n#         for batch_idx, (images, labels) in enumerate(tepoch):\n#             images, labels = images.to(device), labels.to(device)\n#             G.train()\n#             D.train()\n#             target_model.eval()\n        \n#             \"\"\"\n#             Generator Update\n#             \"\"\"\n#             optimizer_G.zero_grad()\n#             perturbations = G(images)  # Recompute perturbations for generator update\n#             g_loss = LossFunctions.total_loss(\n#                 D, target_model,\n#                 alpha, beta, c, images, perturbations, labels\n#             )\n#             g_loss.backward()\n#             optimizer_G.step()\n#             \"\"\"\n#             Discriminator Update\n#             \"\"\"\n#             optimizer_D.zero_grad()\n#             with torch.no_grad():  # Disable gradient tracking for generator during discriminator update\n#                 perturbations = G(images)\n#                 adv_images = torch.clamp(images + perturbations, -1, 1)\n        \n#             d_loss = LossFunctions.gan_loss(D, images, perturbations)\n#             d_loss.backward()\n#             optimizer_D.step() \n\n            \n#             # Track losses and accuracy\n#             g_loss_epoch += g_loss.item()\n#             d_loss_epoch += d_loss.item()\n        \n#             with torch.no_grad():\n#                 benign_output = target_model(images)\n#                 _, benign_predicted = benign_output.max(1)\n#                 adv_output = target_model(adv_images)\n#                 _, adv_predicted = adv_output.max(1)\n        \n#                 correct_benign += (benign_predicted == labels).sum().item()\n#                 correct_adv += (adv_predicted != benign_predicted).sum().item()\n#                 total_samples += labels.size(0)\n        \n#             tepoch.set_postfix({'Batch': batch_idx + 1, 'G_Loss': g_loss.item(), 'D_Loss': d_loss.item()})\n        \n#         g_losses.append(g_loss_epoch / len(train_loader))\n#         d_losses.append(d_loss_epoch / len(train_loader))\n#         # len(train_loader):313 O total_samples:40000\n#         print(f\"len(train_loader):{len(train_loader)} O total_samples:{total_samples}\")\n#         print(f\"correct_adv:{correct_adv} O total_samples:{total_samples}\")\n#         g_accuracies.append(correct_adv / total_samples)\n#         model_accuracies.append(correct_benign / total_samples)\n#         attack_success_rates.append(correct_adv / total_samples)\n\n#         G.eval()\n#         D.eval()\n#         target_model.eval()\n#         val_g_loss_epoch, val_d_loss_epoch = 0.0, 0.0\n#         val_correct_adv, val_correct_benign, val_samples = 0, 0, 0\n#         with torch.no_grad():\n#             for val_images, val_labels in val_loader:\n#                 val_images, val_labels = val_images.to(device), val_labels.to(device)\n\n#                 val_perturbations = G(val_images)\n#                 val_adv_images = torch.clamp(val_images + val_perturbations, -1, 1)\n\n#                 val_d_loss = LossFunctions.gan_loss(D, val_images, val_perturbations)\n#                 val_g_loss = LossFunctions.total_loss(\n#                     D, target_model,\n#                     alpha, beta, c, val_images, val_perturbations, val_labels\n#                 )\n\n#                 val_g_loss_epoch += val_g_loss.item()\n#                 val_d_loss_epoch += val_d_loss.item()\n\n#                 val_benign_output = target_model(val_images)\n#                 _, val_benign_predicted = val_benign_output.max(1)\n#                 val_adv_output = target_model(val_adv_images)\n#                 _, val_adv_predicted = val_adv_output.max(1)\n\n#                 val_correct_benign += (val_benign_predicted == val_labels).sum().item()\n#                 val_correct_adv += (val_adv_predicted != val_labels).sum().item()\n#                 val_samples += val_labels.size(0)\n\n#         g_scheduler.step()\n#         d_scheduler.step()\n        \n#         val_g_losses.append(val_g_loss_epoch / len(val_loader))\n#         val_d_losses.append(val_d_loss_epoch / len(val_loader))\n#         val_g_accuracies.append(val_correct_adv / val_samples)\n#         val_model_accuracies.append(val_correct_benign / val_samples)\n#         val_attack_success_rates.append(val_correct_adv / val_samples)\n\n#         print(f\"Epoch [{epoch+1}/{epochs}], \"\n#               f\"Train G_Loss: {g_losses[-1]:.4f}, D_Loss: {d_losses[-1]:.4f}, Model Accuracy: {model_accuracies[-1]:.4f}, \"\n#               f\"Attack Success Rate: {attack_success_rates[-1]:.4f}, \"\n#               f\"Val G_Loss: {val_g_losses[-1]:.4f}, Val D_Loss: {val_d_losses[-1]:.4f}, \"\n#               f\"Val Model Accuracy: {val_model_accuracies[-1]:.4f}, Val Attack Success Rate: {val_attack_success_rates[-1]:.4f}\")\n#         if val_g_losses[-1] < best_g_loss or val_d_losses[-1] < best_d_loss:\n#             best_g_loss = min(val_g_losses[-1], best_g_loss)\n#             best_d_loss = min(val_d_losses[-1], best_d_loss)\n#             epochs_no_improve = 0\n#         else:\n#             epochs_no_improve += 1\n#             print(f\"Epochs without improvement: {epochs_no_improve}/{patience}\")\n#             if epochs_no_improve >= patience:\n#                 print(f\"Early stopping triggered after {epoch + 1} epochs.\")\n#                 break\n#     return (g_losses, d_losses, g_accuracies, model_accuracies, attack_success_rates,\n#             val_g_losses, val_d_losses, val_g_accuracies, val_model_accuracies, val_attack_success_rates)\n\n# (g_losses, d_losses, g_accuracies, model_accuracies, attack_success_rates, \n#  val_g_losses, val_d_losses, val_g_accuracies, val_model_accuracies, \n#  val_attack_success_rates) = train_gan(\n#     G, D, target_model, train_loader, val_loader,\n#     epochs, optimizer_G, optimizer_D, c, alpha, beta, \n#     g_scheduler, d_scheduler, patience\n# )\n\n# plot_losses(\n#     epochs, g_losses, d_losses, g_accuracies, model_accuracies, \n#     attack_success_rates, val_g_losses, val_d_losses, \n#     val_g_accuracies, val_model_accuracies, val_attack_success_rates\n# )","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"overall_rate, per_class_rate = calculate_attack_success(target_model, test_loader, generator)\n\nprint(f\"Overall Attack Success Rate: {overall_rate * 100:.2f}%\")\nfor i, class_name in enumerate(CLASSES):\n    print(f\"Class {class_name}: {per_class_rate[i] * 100:.2f}%\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"visualize_adversarial_samples(generator, test_loader)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"plot_confidence_histograms(target_model, test_loader, generator)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# def train_gan(\n#     generator, discriminator, target_model, train_loader, \n#     epochs, g_optimizer, d_optimizer, c, alpha, beta, \n#     g_scheduler, d_scheduler, patience\n# ):\n#     g_losses, d_losses, g_accuracies = [], [], []\n#     best_g_loss, best_d_loss = float('inf'), float('inf')\n#     epochs_no_improve = 0\n\n#     for epoch in range(epochs):\n#         correct_adv = 0\n#         g_loss_epoch, d_loss_epoch = 0.0, 0.0\n#         tepoch = tqdm(train_loader, unit=\"batch\", desc=f\"Epoch {epoch+1}/{epochs}\", ncols=100, leave=False)\n\n#         generator.train()\n#         discriminator.train()\n#         for batch_idx, (images, labels) in enumerate(tepoch):\n#             images, labels = images.to(device), labels.to(device)\n\n#             perturbations = generator(images)\n#             adv_images = torch.clamp(images + perturbations, -1, 1)\n\n#             d_optimizer.zero_grad()\n#             d_loss = LossFunctions.gan_loss(\n#                 discriminator, images, perturbations\n#             )\n#             d_loss.backward()\n#             d_optimizer.step()\n\n#             g_optimizer.zero_grad()\n#             g_loss = LossFunctions.total_loss(\n#                 discriminator, target_model, \n#                 alpha, beta, c, images, perturbations\n#             )\n#             g_loss.backward()\n#             g_optimizer.step()\n\n#             g_loss_epoch += g_loss.item()\n#             d_loss_epoch += d_loss.item()\n#             adv_output = target_model(adv_images)\n#             _, predicted = adv_output.max(1)\n#             correct_adv += (predicted != labels).sum().item()\n#             tepoch.set_postfix({'Batch': batch_idx + 1, 'G_Loss': g_loss.item(), 'D_Loss': d_loss.item()})\n\n#         g_losses.append(g_loss_epoch / len(train_loader))\n#         d_losses.append(d_loss_epoch / len(train_loader))\n#         g_accuracies.append(correct_adv / len(train_loader))\n        \n#         print(f\"Epoch [{epoch+1}/{epochs}], Generator Loss: {g_losses[-1]:.4f}, Discriminator Loss: {d_losses[-1]:.4f}, Fooling Accuracy: {g_accuracies[-1]:.4f}\")\n#         generator.eval()\n#         g_scheduler.step()\n        \n#         discriminator.eval()\n#         d_scheduler.step()\n\n#         if g_losses[-1] < best_g_loss or d_losses[-1] < best_d_loss:\n#             best_g_loss = min(g_losses[-1], best_g_loss)\n#             best_d_loss = min(d_losses[-1], best_d_loss)\n#             epochs_no_improve = 0\n#         else:\n#             print(f\"Epochs without improvement: {epochs_no_improve + 1}/{patience}\")\n#             epochs_no_improve += 1\n#             if epochs_no_improve >= patience:\n#                 print(f\"Early stopping triggered after {epoch + 1} epochs.\")\n#                 break\n\n#     return g_losses, d_losses, g_accuracies\n\n# g_losses, d_losses, g_accuracies = train_gan(\n#     generator, discriminator, target_model, train_loader, \n#     epochs, g_optimizer, d_optimizer, c, alpha, beta, \n#     g_scheduler, d_scheduler, patience\n# )\n\n# plot_losses(epochs, g_losses, d_losses, g_accuracies)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# target_class = 0  # Example: Force adversarial images to be classified as \"airplane\" (class 0)\n# fooling_loss = adv_loss_fn(adv_output, torch.full_like(labels, target_class))\n\n# generator = Generator().to(device)\n# discriminator = Discriminator().to(device)\n\n# epochs = 50 \n# lr = 0.001\n# alpha = 1.0  # Weight for GAN loss\n# beta = 10.0  # Weight for hinge loss\n# # c = 0.1  # Perturbation bound\n# c = 8/255 # Perturbation bound (c) = 8/255 for CIFAR-10\n\n# g_optimizer = optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n# d_optimizer = optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))\n\n# g_scheduler = StepLR(g_optimizer, step_size=10, gamma=0.5)\n# d_scheduler = StepLR(d_optimizer, step_size=10, gamma=0.5)\n\n# g_losses, d_losses, g_accuracies = train_gan(\n#     generator, discriminator, target_model, train_loader, \n#     epochs, g_optimizer, d_optimizer, c, alpha, beta, \n#     g_scheduler, d_scheduler, patience\n# )\n\n# plot_losses(epochs, g_losses, d_losses, g_accuracies)\n# overall_rate, per_class_rate = calculate_targeted_attack_success(target_model, test_loader, generator, target_class)\n\n# print(f\"Overall Targeted Attack Success Rate: {overall_rate * 100:.2f}%\")\n# for i, class_name in enumerate(CLASSES):\n#     print(f\"Class {class_name}: {per_class_rate[i] * 100:.2f}%\")\n\n# visualize_adversarial_samples(generator, test_loader)\n# plot_confidence_histograms(target_model, test_loader, generator)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}